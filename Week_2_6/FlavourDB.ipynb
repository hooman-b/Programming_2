{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The provided text describes a segment of a code repository belonging to an integrated omics project, authored by a specific group. The purpose of this code is to process a collection of 936 JSON ingredient files, seeking optimal ingredient substitutions across various recipes, such as replacing eggs in bakery recipes. The procedural steps of this process are outlined as follows:\n",
    "\n",
    "1. **Initial Data Extraction**: The code begins by extracting crucial attributes from the 936 JSON ingredient files. These extracted attributes are then consolidated into a single JSON file.\n",
    "\n",
    "2. **Graph Creation**: The extracted JSON file serves as the basis for generating a graph. In this graph, ingredients function as nodes, while edges are derived from a selected attribute, such as the count of shared molecules between two ingredients. The resulting graph is subsequently visualized through plotting.\n",
    "\n",
    "3. **Graph Embeddings**: Employing the Nodes2Vec algorithm, graph embeddings are generated for all ingredients. These embeddings capture the relationships between ingredients within the graph. To quantify ingredient similarities, cosine similarity and Euclidean distances are computed.\n",
    "\n",
    "4. **Similar Ingredient Identification**: The code identifies ingredients that exhibit the highest similarity to a specified target ingredient.\n",
    "\n",
    "5. **Dimensionality Reduction**: A dimensionality reduction technique is applied to the dataset. Specifically, T-SNE is used to transform the data's dimensions down to two. This facilitates a clearer understanding of ingredient relationships, which are re-evaluated in this reduced space.\n",
    "\n",
    "### How organize and maintainable this code is:\n",
    "After examining the code, it's obvious that it lacks organization and isn't easy to maintain. To address these concerns, it requires significant changes to introduce structure and improve its maintainability. One major issue is the absence of a clear structure, and another problem is the complete lack of functions. This leads to repeated blocks of code appearing throughout the codebase. Additionally, there are various other significant and minor issues that need attention.\n",
    "\n",
    "In the following part, I will review the code and mention all the strong and weak points of it. Each piece of code contain some internal comments, but if it was necessary, I added some extra comments outside of the code shells. The title of these extra comments is 'General points'. Also, I assigned 'Author notation' to the documentaion provided by the author.\n",
    "\n",
    "Thus, let's begin the analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author notation\n",
    "Integration of 936 JSON ingredient files downloaded from Flavour DB into a unified file named \"integrated_data\". Extract the attribute \"entity_alias_readable\" representing the ingredient and its sub-attribute \"molecules\". Within \"molecules\", extract the attributes \"flavor_profile\", \"fooddb_flavor_profile\", and \"common_name\" representing the molecule name, taste, and flavor information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General points:\n",
    "\n",
    "1. she mentioned a description about the following piece of code, which is quite informative. Consequently, I acquire a sense about the code before reading it.\n",
    "\n",
    "2. the description provided about the first piece of the code is a little bit confusing especially the following part: 'Within \"molecules\", extract the attributes \"flavor_profile\", \"fooddb_flavor_profile\", and \"common_name\" representing the molecule name, taste, and flavor information.'. the reason is that there is no order in introducing the attribute and their description, and a person should infer that which description belong to which attribute based on the name of each attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated JSON file created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#=========================================================\n",
    "# Specify the folder path containing the JSON files\n",
    "folder_path = \"C:/Users/ghaza/Downloads/ingrediants\"\n",
    "\"\"\"\n",
    "In my opinion one of the best way of reading a path is by using config\n",
    "file since it prevents us from hardcoding. In this code everytime she\n",
    "wants to change the path she should change a part of the main body of code\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Create a dictionary to store the integrated data\n",
    "integrated_data = []\n",
    "\"\"\"\n",
    "she wrote the above comment that she is about to make a dictionary, \n",
    "but she made a list!!! I believe that This should not happen for a \n",
    "data scientist \n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "#####\n",
    "# 1 #\n",
    "#####\n",
    "# Check if the output file already exists\n",
    "output_file_path = \"C:/Users/ghaza/Downloads/integrated_data.json\"\n",
    "if os.path.exists(output_file_path):\n",
    "    os.remove(output_file_path)\n",
    "#####\n",
    "# 1 #\n",
    "#####\n",
    "\"\"\"\n",
    "These two sections can combine with each other to form a function first, \n",
    "then a preferably a list or even a dictionary from all the json files paths\n",
    "can be make and return from this function. Consequently, the mentioned list\n",
    "can be used as the input of the next part or function of the code. The reason\n",
    "for this is that first she can break this complex structure into a group of \n",
    "simpler building blocks. Second, each function or code building block operates\n",
    "only one task(single task), for example, a function is responsible for making the path, and\n",
    "another one is responsible for reading configuration file. Third, the code can\n",
    "acquire a structure and even architecture which makes it quite more understandable,\n",
    "and more functional.\n",
    "\"\"\"\n",
    "#####\n",
    "# 2 #\n",
    "#####\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "#####\n",
    "# 2 #\n",
    "#####\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "#####\n",
    "# 3 #\n",
    "#####\n",
    "        # Read the JSON file\n",
    "        with open(file_path, \"r\") as file:\n",
    "            file_data = json.load(file)\n",
    "            \n",
    "            ingredient = file_data.get(\"entity_alias_readable\", \"\")\n",
    "            molecules = file_data.get(\"molecules\", [])\n",
    "            category = file_data.get(\"category_readable\", \"\")\n",
    "\n",
    "            # Iterate over molecules and extract relevant data\n",
    "            for molecule in molecules:\n",
    "                molecule_info = {\n",
    "                    \"flavor\": molecule.get(\"flavor_profile\", \"\"),\n",
    "                    \"molecule\": molecule.get(\"common_name\", \"\"),\n",
    "                    \"fooddb_flavor_profile\": molecule.get(\"fooddb_flavor_profile\", \"\"),\n",
    "                    \"taste\": molecule.get(\"taste\", \"\")\n",
    "                    \n",
    "                }\n",
    "                ingredient_data = {\n",
    "                    \"ingredients\": ingredient,\n",
    "                    \"category\":[category],\n",
    "                    \"molecules\": [molecule_info]\n",
    "                    \n",
    "                }\n",
    "                \"\"\"\n",
    "                This part is good. She kept th code simple and practical and\n",
    "                try to extract the feature that she wants by only using get command.\n",
    "                But, in my opinion, the only part that can be optimized is 'molecules'\n",
    "                for loop. She could have used list comprehension instead of for loop, \n",
    "                which is quite faster and there is no need for an extra loop inside the\n",
    "                main loop.\n",
    "                \"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "#####\n",
    "# 4 #\n",
    "#####\n",
    "                # Check if ingredient already exists in integrated_data\n",
    "                existing_ingredient = next((item for item in integrated_data if item[\"ingredients\"] == ingredient), None)\n",
    "\n",
    "                # If ingredient already exists, append molecule to existing ingredient\n",
    "                if existing_ingredient:\n",
    "                    existing_ingredient[\"molecules\"].append(molecule_info)\n",
    "                else:\n",
    "                    integrated_data.append(ingredient_data)\n",
    "                \n",
    "                \"\"\"\n",
    "                This part can be improved by using dictionaries. If she had assigned 'integrated_data'\n",
    "                to be a dictionary instead of a list, she would have been able to find an ingradient \n",
    "                by using an if clause only without need of using next function. Moreover, next sentence\n",
    "                has more than 100 character, so breaking it into sentences can help us to abide PEP8 rules.\n",
    "                \"\"\"\n",
    "\"\"\"\n",
    "parts '3' and '4' can be combined in a function with the name of for example 'making_integrated_data'.\n",
    "This can help us to modularize the code even better, and limit each function responsibility to one task. \n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "#####\n",
    "# 5 #\n",
    "#####\n",
    "\n",
    "# Write the integrated data into the output file\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    json.dump(integrated_data, output_file, indent=4)\n",
    "\n",
    "print(\"Integrated JSON file created successfully.\")\n",
    "\"\"\"\n",
    "This part is good. She saved the 'integrated_data' as a json file.\n",
    "So, she actually keep the part of the main json file that she wants\n",
    "and then save it in another file, which is quite good.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Part '5' can be a single function whose duty is to save the integrated\n",
    "data as a json file in the out_put path.\n",
    "\"\"\"\n",
    "#=========================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General points:\n",
    "1. This peice of code does not any structure and architecture. it needs a complete set of modularization and rearrangement.\n",
    "2. This piece of code is an example of hard coding. If one wants to use this for other condition, they need to change a part in the main body.\n",
    "3. lack of using config file.\n",
    "5. strong point is that names of the variables can describe what they contain.\n",
    "\n",
    "one example structure can be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example structure\n",
    "\n",
    "def config():\n",
    "    pass\n",
    "\n",
    "def making_file_paths_list():\n",
    "    pass\n",
    "\n",
    "def making_integrated_data():\n",
    "    pass\n",
    "\n",
    "def saving_file():\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make list of ingrediants names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "# Read the file\n",
    "with open('C:/Users/ghaza/Downloads/integrated_data.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the ingredient names\n",
    "ingredient_names = [item['ingredients'] for item in data]\n",
    "\n",
    "# Print the ingredient names\n",
    "ingredient_names\n",
    "\"\"\"\n",
    "First, she imported json twice!! This again stems in lack of order in \n",
    "writing this code. The best way to manage importing internal modules is\n",
    "to make a seperate cell and put all the modules inside that cell when using\n",
    "jupyter notebook.\n",
    "Second, it can be better to make a function to extract some of the features \n",
    "of this dataset. In that way she could have visually presented some of the \n",
    "key features of the dataset to herself and her colligues.\n",
    "Third, she used list comprehension which is quite nice.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/Users/ghaza/Downloads/ingredient_names.txt'\n",
    "\n",
    "# Create a dictionary with the 'ingredients' key and the ingredient names list as the value\n",
    "data =  ingredient_names\n",
    "\n",
    "# Save the data to the file as JSON\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(data, file)\n",
    "\n",
    "\"\"\"\n",
    "This is just four lines of code, but it contains a number of tremendous problems:\n",
    "First, again the path is used in the main body instead of config file.\n",
    "Second, the comments written here is more misleading than helpful to undestand the code.\n",
    "Indeed, she mentioned that she is making a dictionary, but something that she did is to\n",
    "assign a new name to the list that is made in the privious coding shell. So, when she tried\n",
    "to save 'data' as a json file somewhere, she just saved the mentioned list.\n",
    "Third, she wrote the same piece of code twice (the part used for saving the json file). \n",
    "However, if she made 'saving_file' function, she could just call the function here.\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author notation\n",
    "The resulting graph visually represents the relationships between ingredients, with edges indicating the presence of shared\n",
    "molecules and the weight (number of shared molecules) displayed as labels on the edges.\n",
    "\n",
    "### General points\n",
    "very good clarification about task that the following piece of code will perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================================\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\"\"\"\n",
    "Again!!! importing modules at the middle of the program, beside pickle rest of the\n",
    "have been imported earlier. json module imported THREE times untill now.\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Read the JSON file\n",
    "with open('C:/Users/ghaza/Downloads/integrated_data.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract ingredient names, molecules, categories, and colors\n",
    "ingredients_data = data\n",
    "ingredients = []\n",
    "category_colors = {}  # Dictionary to store category colors\n",
    "color_index = 0  # Counter for assigning colors\n",
    "\"\"\" \n",
    "I cannot understand why she did this since she could assign 'ingredients_data'\n",
    "to the data before this line. Moreover, 'ingredients' should be 'ingredients_list'\n",
    "to get a sense of its type. Also, this can be correct for 'category_colors'. It should\n",
    "change to 'category_colors_dict'\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "for ingredient in ingredients_data:\n",
    "    ingredient_dict = {\n",
    "        'name': ingredient['ingredients'],\n",
    "        'molecules': [],\n",
    "        'category': ingredient['category'],\n",
    "    }\n",
    "\n",
    "    for molecule in ingredient['molecules']:\n",
    "        ingredient_dict['molecules'].append(molecule['molecule'])\n",
    "    ingredients.append(ingredient_dict)\n",
    "    \"\"\"\n",
    "    This part is completely redundant. She wanted to read the elements of the json file that\n",
    "    she has made priviously in the privious shell and store them into a list. Instead of making\n",
    "    a new dictionary for each ingredient, and append each ingradient to a list, something that\n",
    "    she did before, she should have use a list comprehension. Since, first she wanted all the\n",
    "    information inside the json file, and also she wanted to preserve the structure. The only\n",
    "    thing that she changed is the name of each gradient from 'ingredients' to name, which is\n",
    "    totally redundant. The technique with which she could make the same outcome is as follows:\n",
    "\n",
    "    ingredients_list = [ingredients_data[ingredient] for ingredient in ingredients_data]\n",
    "    \"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "    # Convert the category to a tuple if it's a list\n",
    "    category = ingredient['category']\n",
    "    if isinstance(category, list):\n",
    "        category = tuple(category)\n",
    "\n",
    "    # Check if the category already has a color assigned\n",
    "    if category not in category_colors:\n",
    "        # Assign a new color to the category\n",
    "        category_colors[category] = f'C{color_index}'\n",
    "        color_index += 1\n",
    "    \"\"\"\n",
    "    'category' should be a list!!! because she made a list for category in the ingredient dictionary:\n",
    "    \"category\":[category],\n",
    "    one way can be to make a tuple in the first step, so there would not be any need of double\n",
    "    checking. But rest of this part is good. she made a dictionary of category: color for the\n",
    "    next step.\n",
    "    \"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Create an empty graph\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Iterate over ingredient pairs\n",
    "for i in range(len(ingredients)):\n",
    "    for j in range(i + 1, len(ingredients)):\n",
    "        ing1 = ingredients[i]\n",
    "        ing2 = ingredients[j]\n",
    "\n",
    "        # Check if ing1 and ing2 share a molecule\n",
    "        shared_molecules = set(ing1['molecules']).intersection(ing2['molecules'])\n",
    "        if shared_molecules:\n",
    "            # Add an edge between ing1 and ing2 with the weight of the number of shared molecules\n",
    "            weight = len(shared_molecules)\n",
    "            graph.add_edge(ing1['name'], ing2['name'], weight=weight)\n",
    "\n",
    "            # Assign the category to the nodes\n",
    "            graph.nodes[ing1['name']]['category'] = category\n",
    "            graph.nodes[ing2['name']]['category'] = category\n",
    "\n",
    "# Save the graph using Pickle\n",
    "with open('graph_shared_molecules_weights.pkl', 'wb') as file:\n",
    "    pickle.dump(graph, file)\n",
    "\"\"\"\n",
    "This is a sufficient implementation of making a graph, but there are some problems with it.\n",
    "First, she used dual for loop here, but it is not actuelly necessary. Instead she could\n",
    "have used itertools package:\n",
    "for i, j in itertools.combinations(range(len(ingredients)), 2):\n",
    "The provided code will give her the same result without using two for loops.\n",
    "\n",
    "Second, The category part is completely wrong. Indeed, if you have a look at variable 'caregory',\n",
    "you can see that the last category of the last ingredient stores in it. Consequently, this code \n",
    "will assign the same category to all the nodes of the graph.\n",
    "\n",
    "Third, she again could have used another function to save the graph, but this part of the code does\n",
    "not have any structure.\n",
    "\n",
    "Fourth, again this piece of code does not have any structure. Actually, she could have made a function\n",
    "like 'making_graph' to make the mentioned graph for her.\n",
    "\n",
    "Fifth: she made a list of ingredient above to loop over all the ingredients. Instead, she could only \n",
    "loop through the json file, and gain the same result. Using the following loop:\n",
    "\n",
    "for i, j in itertools.combinations(ingredients, 2):\n",
    "    print(i, j)\n",
    "\n",
    "With this most of the redundant computations and operation that she did can be erased.\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Draw the graph with edge labels, category, and color nodes\n",
    "plt.figure(figsize=(100, 80))\n",
    "pos = nx.spring_layout(graph)\n",
    "node_colors = [category_colors[graph.nodes[node]['category']] for node in graph.nodes()]\n",
    "nx.draw(graph, pos, with_labels=True, node_size=500, node_color=node_colors, edge_color='gray')\n",
    "labels = nx.get_edge_attributes(graph, 'weight')\n",
    "nx.draw_networkx_edge_labels(graph, pos, edge_labels=labels)\n",
    "\n",
    "# Draw category nodes\n",
    "for category, color in category_colors.items():\n",
    "    plt.text(0, 0, str(category), color=color, ha='center', fontsize=8)\n",
    "\n",
    "plt.show()\n",
    "\"\"\"\n",
    "Here she sketched the graph using matplotlib.\n",
    "First, she could have made a function like 'drawing_graph' to sketch this graph, and also,\n",
    "if it is necessary for other parts of the code.\n",
    "\n",
    "Second, as I expected, all the nodes have the same color. the problem has a root in assigning\n",
    "the same category to all the nodes (As you can see, all the nodes are brown).\n",
    "\n",
    "Third, she did not use the category dictionary (category_colors) that she made for the colors\n",
    "of the nodes.\n",
    "\n",
    "Fourth, she made node_colors list that contains the same elements for all the nodes. The reson\n",
    "is that all the nodes' categories are the same.\n",
    "\"\"\"\n",
    "#=========================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General points:\n",
    "1. Again this piece of code has the lack of structure, which I belieave makes it hard for the writer to understand some of the severe problems that this code has.\n",
    "2. Part of the code is redundant. The writer could have implemented all of these operation with about one third less lines of code.\n",
    "3. The code is hard-coded; thus, the trivial change in the code requires the writer to change the main body of the code.\n",
    "4. Code contains some logical errors such as assigning wrong category to the nodes that make the outcome invalid.\n",
    "5. Assigned names to the variables are not suffice. The reason is that one cannot find the type of the variable from its name that make everything more complicated for a reader. It also make everything more complicated for the writer especially if she would come back to code after a while.\n",
    "6. The code is unnecessarily complex.\n",
    "\n",
    "Moreover, the above code can be organized in the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_graph():\n",
    "    pass\n",
    "\n",
    "def drawing_graph():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================================\n",
    "from node2vec import Node2Vec\n",
    "\"\"\"\n",
    "Again she imported another module at the middle of the code.\n",
    "Indded, this can be personal since one wants to show that where is \n",
    "the module used in the code. However, I personally do NOT like this notation.\n",
    "Because, first, this notation can be utilized in jupyter notebook only, and\n",
    "cannot be used in the .py files. Moreover, I believe it can be messy to import\n",
    "a module at the middle of the code.\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Generate random walks using Node2Vec\n",
    "# Generate random walks using Node2Vec with tuned parameters\n",
    "node2vec = Node2Vec(graph, dimensions=128, walk_length=80, num_walks=300)\n",
    "model = node2vec.fit(window=10, min_count=1)\n",
    "\n",
    "\"\"\"\n",
    "She used Node2Vec which is the great choice for this problem since the mentioned\n",
    "package is used to learn node embeddings in graph data. This package is based on word2vec and \n",
    "aims to learn embeddings for nodes in such a way that nodes with similar network neighborhoods \n",
    "end up having similar embeddings. Consequently, the nodes with stronger edges are\n",
    "more likely to be from the same community, and more tightly pack in a graph representation.\n",
    "This embeding can be used for various downstream tasks, such as node classification,\n",
    "link prediction, and graph visualization. \n",
    "\n",
    "The problem with her model is that she mentioned the hyper parameters of this model is \n",
    "TUNED; However, I cannot find any approaches such as GridSearchCV used to tune the hyper\n",
    "parameters. Moreover, when I checked the package's github, I found that in fact two of the\n",
    "three parameters are the default values ('dimensions', 'walk_length'). Consequently, I believe\n",
    "that no tuning method had been used here.\n",
    "link: https://github.com/eliorc/node2vec \n",
    "She could have make a dictionary of multiple models using GridSearchCV, and then evaluate these\n",
    "methods downstream.\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Retrieve node embeddings for available ingredients\n",
    "ingredient_embeddings = {}\n",
    "for ingredient_dict in ingredients:\n",
    "    ingredient_name = ingredient_dict['name']\n",
    "    if ingredient_name in model.wv:\n",
    "        embedding = model.wv[ingredient_name]\n",
    "        ingredient_embeddings[ingredient_name] = embedding\n",
    "    else:\n",
    "        continue\n",
    "\"\"\"\n",
    "In this part she wants to make a dictionary of ingradient_name: embedding.\n",
    "While it can be a good approach to organize all the embeddings in a dictionary, \n",
    "she could use dictionary comprehenshion to make this. Moreover, the name 'ingredient_embeddings'\n",
    "is not a good representative for a dictionary. The dictionary comprehension can be:\n",
    "ingred_embed_dict = {ingredient_dict['name']:model.wv[ingredient_dict['name']]\n",
    "                     for ingredient_dict in ingredients if ingredient_dict['name'] in model.wv}\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Points\n",
    "1. the model was not tuned.\n",
    "2. The model can be a part of a function or even a class (which is far away beyond the scope of this code), so it makes it easier to use the model.\n",
    "3. A function of combination od Node2Vec and GridSearchCV would be the best function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "#=========================================================\n",
    "# Calculate different similarity matrices\n",
    "cosine_similarity_matrix = cosine_similarity(list(ingredient_embeddings.values()))\n",
    "euclidean_distance_matrix = euclidean_distances(list(ingredient_embeddings.values()))\n",
    "\n",
    "# Example: Find top 5 ingredients similar to \"Egg\" using different similarity measures\n",
    "target_ingredient = \"Egg\"\n",
    "target_embedding = ingredient_embeddings[target_ingredient]\n",
    "target_index = list(ingredient_embeddings.keys()).index(target_ingredient)\n",
    "\n",
    "# Cosine similarity\n",
    "similar_indices_cosine = cosine_similarity_matrix[target_index].argsort()[::-1][1:30]\n",
    "similar_ingredients_cosine = [list(ingredient_embeddings.keys())[i] for i in similar_indices_cosine]\n",
    "\n",
    "# Euclidean distance\n",
    "similar_indices_euclidean = euclidean_distance_matrix[target_index].argsort()[1:30]\n",
    "similar_ingredients_euclidean = [list(ingredient_embeddings.keys())[i] for i in similar_indices_euclidean]\n",
    "\n",
    "print(\"Ingredients similar to\", target_ingredient, \"using different similarity measures:\")\n",
    "print(\"Cosine similarity:\")\n",
    "for ingredient in similar_ingredients_cosine:\n",
    "    category = next((item['category'] for item in ingredients if item['name'] == ingredient), None)\n",
    "    if category and category[0] not in ['Meat', 'Seafood','Fish','Fungus']:\n",
    "        print(f\"Ingredient: {ingredient}, Category: {category}\")\n",
    "\n",
    "print(\"Euclidean distance:\")\n",
    "for ingredient in similar_ingredients_euclidean:\n",
    "    category = next((item['category'] for item in ingredients if item['name'] == ingredient), None)\n",
    "    if category and category[0] not in ['Meat', 'Seafood','Fish','Fungus']:\n",
    "        print(f\"Ingredient: {ingredient}, Category: {category}\")\n",
    "\n",
    "\"\"\"\n",
    "In my opinion, this piece of code, by far, is the best part of this notebook in terms of\n",
    "readability and efficiency. However, There are some points with which one can improve it:\n",
    "\n",
    "First, she could have put all of these materials in a function whose inputs are ingradient embeddings\n",
    "dictionary, target ingradient, number of top match ingradients with the target, and list of categories\n",
    "that the ingradients should not be in them such as 'Meat' and so on. And, its output can be the list of\n",
    "ingradient and their categories. Moreover, one can even make the function more interactive by puting the\n",
    "name of the similarity metric as an input.\n",
    "\n",
    "Second, there are a few comments in the code, and should a little bit more especially for the last part\n",
    "of this code. While the comments in the first part of this piece is suffice, it is absolutely missleading.\n",
    "she wrote that 'Find top 5 ingredients similar to \"Egg\" using different similarity measures'; however, she \n",
    "tried to find the first '30' most similar ingredients which can be quite misleading.\n",
    "\n",
    "Third, the code is hard-coded. By transfering this piece of code in a function, one can make it more robust. \n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#=========================================================\n",
    "# Perform dimensionality reduction on ingredient embeddings\n",
    "embeddings = np.array(list(ingredient_embeddings.values()))\n",
    "ingredient_names = list(ingredient_embeddings.keys())\n",
    "\n",
    "# Use t-SNE for dimensionality reduction\n",
    "tsne = TSNE(n_components=2)\n",
    "reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "\"\"\"\n",
    "The first part of this piece of code is good. She made a dimensionality reduction\n",
    "model, in this case T-SNE. \n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Get unique categories\n",
    "categories = set()\n",
    "for ingredient in ingredients:\n",
    "    categories.add(ingredient['category'][0])\n",
    "\n",
    "# Assign colors to categories\n",
    "category_colors = {}\n",
    "color_index = 0\n",
    "for category in categories:\n",
    "    category_colors[category] = f'C{color_index}'\n",
    "    color_index += 1\n",
    "\n",
    "\"\"\"\n",
    "This part contains repititions:\n",
    "'category_colors' was made in another privious shell, so instead of making it again\n",
    "she should have used the privious one. Also, there is no need of making 'categories'\n",
    "since she assign the distinct categories as the keys of the above 'category_colors'\n",
    "; consequently, she could have used the above dictionary. As a result, this part is \n",
    "completely redundant.\n",
    "However, if the writer wants to keep this part, she should have used set and dictionary\n",
    "comprehensions.\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Plot the reduced embeddings without ingredient names and color nodes based on categories\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(len(ingredient_names)):\n",
    "    category = next((ingredient['category'][0] for ingredient in ingredients if ingredient['name'] == ingredient_names[i]), None)\n",
    "    if category:\n",
    "        plt.scatter(reduced_embeddings[i, 0], reduced_embeddings[i, 1], color=category_colors[category])\n",
    "\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.title(\"Ingredient Embeddings Visualization\")\n",
    "plt.show()\n",
    "\"\"\"\n",
    "this part of the code can be optimized by using the following tips:\n",
    "First, organize this piece of code in a function. This can be quite important in maintainability and\n",
    "versatility of the code.\n",
    "\n",
    "Second, using for loop to find the category and plotting point by point can be quite time-consuming and\n",
    "computation excessive especially when working with a large dataset. Instead, one can use dictionary \n",
    "comprehension to first map ingredient names to their categories, then make a list of color based on the\n",
    "ingrediant categories. Finally, use them in plt.scatter to sketch the scatter plot. Also, instead of using\n",
    "each point as the x and y axes of the plot at each iteration, one can make the list of x and y components,\n",
    "then sketch them collectively on the plot.   \n",
    "\"\"\"\n",
    "#=========================================================\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author notation\n",
    "The resulting graph visually represents the relationships between ingredients, with edges indicating the presence of shared flavors and the weight (number of shared flavors) displayed as labels on the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General points:\n",
    "The above pieces of codes are all the materials that the author presented in this notebook. Indeed, rest of the code are all repeating the above pieces of codes, but with changing one pre-condition. For example, in the next repeatition of the code, the author utilized 'fooddb_flavor_profile' as the main feature of the ingradient, and tried to find mutual (shared) 'fooddb flavour' between them instead of using molecules. \n",
    "\n",
    "The author had to change only two parts in each repitition. First, one item in each ingradient dictionary ('molecules' item), and a part in making graph edges in which the condition of having edge between two nodes because it should be based on the mentioned new feature. Both of the mentioned changes can be implemented conviniently if this code has any kind of structure!! Actually, if the author modularized her code, she would have been able to add the mentioned changes as the input of the functions instead of changing the main body each time.\n",
    "\n",
    " Moreover, she copied each piece of code everytime that she wanted to examine a new feature that even make the code more hard-coded. Consequently, the most important and urgent correction for this code other than all the points that I have mentioned above is to construct a flexible and versatile structure for this code.\n",
    "\n",
    "In the following parts, I will only mark the repeated parts, and also the converted sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#=========================================================\n",
    "# Read the JSON file\n",
    "with open('C:/Users/ghaza/Downloads/integrated_data.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract ingredient names, molecules, and categories\n",
    "ingredients_data = data\n",
    "ingredients = []\n",
    "for ingredient in ingredients_data:\n",
    "    ingredient_dict = {\n",
    "        'name': ingredient['ingredients'],\n",
    "        'molecules': {},\n",
    "        'category': ingredient['category']\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    the same code\n",
    "    \"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "    for molecule in ingredient['molecules']:\n",
    "        ingredient_dict['molecules'][molecule['molecule']] = molecule['fooddb_flavor_profile']\n",
    "    ingredients.append(ingredient_dict)\n",
    "\"\"\"\n",
    "changing one feature\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Create an empty graph\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Iterate over ingredient pairs\n",
    "for i in range(len(ingredients)):\n",
    "    for j in range(i + 1, len(ingredients)):\n",
    "        ing1 = ingredients[i]\n",
    "        ing2 = ingredients[j]\n",
    "\n",
    "        # Find shared molecules\n",
    "        shared_molecules = set(ing1['molecules'].keys()) & set(ing2['molecules'].keys())\n",
    "\n",
    "        # Process shared molecules and flavors\n",
    "        shared_flavors = []\n",
    "        for molecule in shared_molecules:\n",
    "            flavors = ing1['molecules'][molecule].split(\"@\")\n",
    "            shared_flavors.extend(flavor for flavor in flavors)\n",
    "        weight = len(set(shared_flavors))\n",
    "\n",
    "        # Add an edge with the weight between ing1 and ing2\n",
    "        if weight > 0:\n",
    "            graph.add_edge(ing1['name'], ing2['name'], weight=weight)\n",
    "\n",
    "\"\"\"\n",
    "The author made a graph and found that it is wrong, and she did not even erase this part\n",
    "from the body of her code, and just run the program!!!!!\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Create a mapping of categories to colors\n",
    "category_colors = {}\n",
    "color_index = 0\n",
    "for ingredient in ingredients:\n",
    "    category = ingredient['category']\n",
    "    if isinstance(category, list):\n",
    "        category = tuple(category)\n",
    "    if category not in category_colors:\n",
    "        category_colors[category] = f'C{color_index}'\n",
    "        color_index += 1\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Assign category colors to nodes\n",
    "node_colors = [category_colors[tuple(ingredient['category'])] for ingredient in ingredients]\n",
    "\n",
    "# Remove duplicate ingredients\n",
    "unique_ingredients = []\n",
    "ingredient_names = set()  # Keep track of ingredient names\n",
    "for ingredient in ingredients:\n",
    "    name = ingredient['name']\n",
    "    if name not in ingredient_names:\n",
    "        unique_ingredients.append(ingredient)\n",
    "        ingredient_names.add(name)\n",
    "\n",
    "# Use unique_ingredients list for further processing and graph creation\n",
    "ingredients = unique_ingredients\n",
    "node_names = [ingredient['name'] for ingredient in ingredients]  # Extract the unique ingredient names\n",
    "\n",
    "# Update node_colors based on the unique ingredient names\n",
    "node_colors = [node_colors[node_names.index(name)] for name in node_names]\n",
    "\"\"\"\n",
    "This one is different from other parts; however, she only used this part in this specific repeatition.\n",
    "I am pretty sure that seh could find the unique ingredient from other practical ways.\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Create a new graph with unique ingredients\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Iterate over ingredient pairs\n",
    "for i in range(len(ingredients)):\n",
    "    for j in range(i + 1, len(ingredients)):\n",
    "        ing1 = ingredients[i]\n",
    "        ing2 = ingredients[j]\n",
    "\n",
    "        # Find shared molecules\n",
    "        shared_molecules = set(ing1['molecules'].keys()) & set(ing2['molecules'].keys())\n",
    "\n",
    "        # Process shared molecules and flavors\n",
    "        shared_flavors = []\n",
    "        for molecule in shared_molecules:\n",
    "            flavors = ing1['molecules'][molecule].split(\"@\")\n",
    "            shared_flavors.extend(flavor for flavor in flavors)\n",
    "        weight = len(set(shared_flavors))\n",
    "\n",
    "        # Add an edge with the weight between ing1 and ing2\n",
    "        if weight > 0:\n",
    "            graph.add_edge(ing1['name'], ing2['name'], weight=weight)\n",
    "\n",
    "\"\"\"\n",
    "All the parts of the graph are the same the only part which is different is the\n",
    "condition to have an edge between two nodes, and the weight of the nodes\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Save the graph using Pickle\n",
    "with open('graph_shared_flavors_weights.pkl', 'wb') as file:\n",
    "    pickle.dump(graph, file)\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(100, 80))\n",
    "pos = nx.spring_layout(graph, seed=42)  # Set a fixed seed for consistent layout\n",
    "weights = nx.get_edge_attributes(graph, 'weight')\n",
    "\n",
    "# Convert node_colors to a list of colors corresponding to node_names\n",
    "node_colors = [node_colors[node_names.index(node)] for node in graph.nodes]\n",
    "\n",
    "# Draw nodes with correct colors\n",
    "nx.draw_networkx_nodes(graph, pos, node_color=node_colors, node_size=2000, cmap='rainbow')\n",
    "nx.draw_networkx_edges(graph, pos)\n",
    "nx.draw_networkx_labels(graph, pos, font_size=20)\n",
    "\n",
    "# Draw edge labels\n",
    "nx.draw_networkx_edge_labels(graph, pos, edge_labels=weights, font_size=100)\n",
    "\n",
    "# Draw category nodes\n",
    "for category, color in category_colors.items():\n",
    "    plt.text(0, 0, str(category), color=color, ha='center', fontsize=8)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "the same functionality, but she tried another code to create the graph, which is\n",
    "absolutely unnecessary.\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "#=========================================================\n",
    "# Generate random walks using Node2Vec\n",
    "# Generate random walks using Node2Vec with tuned parameters\n",
    "node2vec = Node2Vec(graph, dimensions=128, walk_length=80, num_walks=300)\n",
    "model = node2vec.fit(window=10, min_count=1)\n",
    "\n",
    "\n",
    "# Retrieve node embeddings for available ingredients\n",
    "ingredient_embeddings = {}\n",
    "for ingredient_dict in ingredients:\n",
    "    ingredient_name = ingredient_dict['name']\n",
    "    if ingredient_name in model.wv:\n",
    "        embedding = model.wv[ingredient_name]\n",
    "        ingredient_embeddings[ingredient_name] = embedding\n",
    "    else:\n",
    "        continue\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================================\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "# Calculate different similarity matrices\n",
    "cosine_similarity_matrix = cosine_similarity(list(ingredient_embeddings.values()))\n",
    "euclidean_distance_matrix = euclidean_distances(list(ingredient_embeddings.values()))\n",
    "\n",
    "# Example: Find top 5 ingredients similar to \"Egg\" using different similarity measures\n",
    "target_ingredient = \"Egg\"\n",
    "target_embedding = ingredient_embeddings[target_ingredient]\n",
    "target_index = list(ingredient_embeddings.keys()).index(target_ingredient)\n",
    "\n",
    "# Cosine similarity\n",
    "similar_indices_cosine = cosine_similarity_matrix[target_index].argsort()[::-1][1:30]\n",
    "similar_ingredients_cosine = [list(ingredient_embeddings.keys())[i] for i in similar_indices_cosine]\n",
    "\n",
    "# Euclidean distance\n",
    "similar_indices_euclidean = euclidean_distance_matrix[target_index].argsort()[1:30]\n",
    "similar_ingredients_euclidean = [list(ingredient_embeddings.keys())[i] for i in similar_indices_euclidean]\n",
    "\n",
    "print(\"Ingredients similar to\", target_ingredient, \"using different similarity measures:\")\n",
    "print(\"Cosine similarity:\")\n",
    "for ingredient in similar_ingredients_cosine:\n",
    "    category = next((item['category'] for item in ingredients if item['name'] == ingredient), None)\n",
    "    if category and category[0] not in ['Meat', 'Seafood','Fish','Fungus']:\n",
    "        print(f\"Ingredient: {ingredient}, Category: {category}\")\n",
    "\n",
    "print(\"Euclidean distance:\")\n",
    "for ingredient in similar_ingredients_euclidean:\n",
    "    category = next((item['category'] for item in ingredients if item['name'] == ingredient), None)\n",
    "    if category and category[0] not in ['Meat', 'Seafood','Fish','Fungus']:\n",
    "        print(f\"Ingredient: {ingredient}, Category: {category}\")\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================================\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perform dimensionality reduction on ingredient embeddings\n",
    "embeddings = np.array(list(ingredient_embeddings.values()))\n",
    "ingredient_names = list(ingredient_embeddings.keys())\n",
    "\n",
    "# Use t-SNE for dimensionality reduction\n",
    "tsne = TSNE(n_components=2)\n",
    "reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Get unique categories\n",
    "categories = set()\n",
    "for ingredient in ingredients:\n",
    "    categories.add(ingredient['category'][0])\n",
    "\n",
    "# Assign colors to categories\n",
    "category_colors = {}\n",
    "color_index = 0\n",
    "for category in categories:\n",
    "    category_colors[category] = f'C{color_index}'\n",
    "    color_index += 1\n",
    "\n",
    "# Plot the reduced embeddings without ingredient names and color nodes based on categories\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(len(ingredient_names)):\n",
    "    category = next((ingredient['category'][0] for ingredient in ingredients if ingredient['name'] == ingredient_names[i]), None)\n",
    "    if category:\n",
    "        plt.scatter(reduced_embeddings[i, 0], reduced_embeddings[i, 1], color=category_colors[category])\n",
    "\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.title(\"Ingredient Embeddings Visualization\")\n",
    "plt.show()\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author notation\n",
    "In this modified code, each ingredient is connected to the top 10 ingredients that have the most shared flavors with it. The resulting graph will reflect these connections. The top 10 ingredients with the most shared flavors are connected to the current ingredient in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#=========================================================\n",
    "# Read the JSON file\n",
    "with open('C:/Users/ghaza/Downloads/integrated_data.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract ingredient names, flavors, and categories\n",
    "ingredients_data = data\n",
    "ingredients = []\n",
    "category_colors = {}\n",
    "color_index = 0\n",
    "\n",
    "for ingredient in ingredients_data:\n",
    "    ingredient_dict = {\n",
    "        'name': ingredient['ingredients'],\n",
    "        'flavors': [],\n",
    "        'category': ingredient['category']\n",
    "    }\n",
    "    \"\"\"\n",
    "    the same code\n",
    "    \"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "    for molecule in ingredient['molecules']:\n",
    "        ingredient_dict['flavors'].extend(molecule['flavor'].split('@'))\n",
    "    ingredients.append(ingredient_dict)\n",
    "    \"\"\"\n",
    "    changing one feature\n",
    "    \"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "    # Store the category-color mapping\n",
    "    category = ingredient['category']\n",
    "    if isinstance(category, list):\n",
    "        category = tuple(category)\n",
    "    if category not in category_colors:\n",
    "        category_colors[category] = f'C{color_index}'\n",
    "        color_index += 1\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Create an empty graph\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Iterate over ingredients\n",
    "for i in range(len(ingredients)):\n",
    "    ing1 = ingredients[i]\n",
    "    shared_counts = []\n",
    "\n",
    "    # Calculate shared flavor counts with other ingredients\n",
    "    for j in range(len(ingredients)):\n",
    "        if i != j:\n",
    "            ing2 = ingredients[j]\n",
    "            shared_count = len(set(ing1['flavors']).intersection(ing2['flavors']))\n",
    "            shared_counts.append((j, shared_count))\n",
    "\n",
    "    # Sort by shared flavor counts in descending order\n",
    "    shared_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Connect ing1 to the top 10 ingredients with the most shared flavors\n",
    "    for j, _ in shared_counts[:10]:\n",
    "        ing2 = ingredients[j]\n",
    "        graph.add_edge(ing1['name'], ing2['name'])\n",
    "\"\"\"\n",
    "All the parts of the graph are the same the only part which is different is the\n",
    "condition to have an edge between two nodes, and the weight of the nodes\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Save the graph using Pickle\n",
    "with open('graph_most_shared_flavors.pkl', 'wb') as file:\n",
    "    pickle.dump(graph, file)\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(100, 80))  # Adjust the figure size as desired (width, height)\n",
    "\n",
    "# Use spring layout with fixed seed for consistent layout\n",
    "pos = nx.spring_layout(graph, seed=42)\n",
    "\n",
    "# Draw nodes with correct colors based on categories\n",
    "for ingredient in ingredients:\n",
    "    category = ingredient['category']\n",
    "    if isinstance(category, list):\n",
    "        category = tuple(category)\n",
    "    nx.draw_networkx_nodes(\n",
    "        graph,\n",
    "        pos,\n",
    "        nodelist=[ingredient['name']],\n",
    "        node_color=category_colors[category],\n",
    "        node_size=2000,\n",
    "        cmap='rainbow'\n",
    "    )\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(graph, pos)\n",
    "\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(graph, pos, font_size=20)\n",
    "\n",
    "# Draw category nodes\n",
    "for category, color in category_colors.items():\n",
    "    plt.text(0, 0, str(category), color=color, ha='center', fontsize=8)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "the same functionality, but she tried another code to create the graph, which is\n",
    "absolutely unnecessary.\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "#=========================================================\n",
    "# Generate random walks using Node2Vec\n",
    "node2vec = Node2Vec(graph, dimensions=64, walk_length=30, num_walks=200)\n",
    "model = node2vec.fit(window=10, min_count=1)\n",
    "\n",
    "# Retrieve node embeddings for available ingredients\n",
    "ingredient_embeddings = {}\n",
    "for ingredient_dict in ingredients:\n",
    "    ingredient_name = ingredient_dict['name']\n",
    "    if ingredient_name in model.wv:\n",
    "        embedding = model.wv[ingredient_name]\n",
    "        ingredient_embeddings[ingredient_name] = embedding\n",
    "    else:\n",
    "        continue\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================================\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "# Calculate different similarity matrices\n",
    "cosine_similarity_matrix = cosine_similarity(list(ingredient_embeddings.values()))\n",
    "euclidean_distance_matrix = euclidean_distances(list(ingredient_embeddings.values()))\n",
    "\n",
    "# Example: Find top 5 ingredients similar to \"Egg\" using different similarity measures\n",
    "target_ingredient = \"Egg\"\n",
    "target_embedding = ingredient_embeddings[target_ingredient]\n",
    "target_index = list(ingredient_embeddings.keys()).index(target_ingredient)\n",
    "\n",
    "# Cosine similarity\n",
    "similar_indices_cosine = cosine_similarity_matrix[target_index].argsort()[::-1][1:30]\n",
    "similar_ingredients_cosine = [list(ingredient_embeddings.keys())[i] for i in similar_indices_cosine]\n",
    "\n",
    "# Euclidean distance\n",
    "similar_indices_euclidean = euclidean_distance_matrix[target_index].argsort()[1:30]\n",
    "similar_ingredients_euclidean = [list(ingredient_embeddings.keys())[i] for i in similar_indices_euclidean]\n",
    "\n",
    "print(\"Ingredients similar to\", target_ingredient, \"using different similarity measures:\")\n",
    "print(\"Cosine similarity:\")\n",
    "for ingredient in similar_ingredients_cosine:\n",
    "    category = next((item['category'] for item in ingredients if item['name'] == ingredient), None)\n",
    "    if category and category[0] not in ['Meat', 'Seafood','Fish','Fungus']:\n",
    "        print(f\"Ingredient: {ingredient}, Category: {category}\")\n",
    "\n",
    "print(\"Euclidean distance:\")\n",
    "for ingredient in similar_ingredients_euclidean:\n",
    "    category = next((item['category'] for item in ingredients if item['name'] == ingredient), None)\n",
    "    if category and category[0] not in ['Meat', 'Seafood','Fish','Fungus']:\n",
    "        print(f\"Ingredient: {ingredient}, Category: {category}\")\n",
    "\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================================\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perform dimensionality reduction on ingredient embeddings\n",
    "embeddings = np.array(list(ingredient_embeddings.values()))\n",
    "ingredient_names = list(ingredient_embeddings.keys())\n",
    "\n",
    "# Use t-SNE for dimensionality reduction\n",
    "tsne = TSNE(n_components=2)\n",
    "reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Get unique categories\n",
    "categories = set()\n",
    "for ingredient in ingredients:\n",
    "    categories.add(ingredient['category'][0])\n",
    "\n",
    "# Assign colors to categories\n",
    "category_colors = {}\n",
    "color_index = 0\n",
    "for category in categories:\n",
    "    category_colors[category] = f'C{color_index}'\n",
    "    color_index += 1\n",
    "\n",
    "# Plot the reduced embeddings without ingredient names and color nodes based on categories\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(len(ingredient_names)):\n",
    "    category = next((ingredient['category'][0] for ingredient in ingredients if ingredient['name'] == ingredient_names[i]), None)\n",
    "    if category:\n",
    "        plt.scatter(reduced_embeddings[i, 0], reduced_embeddings[i, 1], color=category_colors[category])\n",
    "\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.title(\"Ingredient Embeddings Visualization\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author notation\n",
    "In this modified code, each ingredient is connected to the top 10 ingredients that have the most shared flavors with it. The resulting graph will reflect these connections. The top 10 ingredients with the most shared flavors are connected to the current ingredient in the graph.The weights of edges are the count af shared flavours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#=========================================================\n",
    "# Read the JSON file\n",
    "with open('C:/Users/ghaza/Downloads/integrated_data.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract ingredient names, flavors, and categories\n",
    "ingredients_data = data\n",
    "ingredients = []\n",
    "categories = set()\n",
    "for ingredient in ingredients_data:\n",
    "    ingredient_dict = {\n",
    "        'name': ingredient['ingredients'],\n",
    "        'flavors': [],\n",
    "        'category': ingredient['category']\n",
    "    }\n",
    "    \"\"\"\n",
    "    the same code\n",
    "    \"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "    for molecule in ingredient['molecules']:\n",
    "        ingredient_dict['flavors'].extend(molecule['flavor'].split('@'))\n",
    "    ingredients.append(ingredient_dict)\n",
    "    categories.add(tuple(ingredient['category']))  # Convert category list to tuple\n",
    "\"\"\"\n",
    "changing one feature\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Create a mapping of categories to colors\n",
    "category_colors = {}\n",
    "color_index = 0\n",
    "for category in categories:\n",
    "    category_colors[category] = f'C{color_index}'\n",
    "    color_index += 1\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Create an empty graph\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Iterate over ingredients\n",
    "for i in range(len(ingredients)):\n",
    "    ing1 = ingredients[i]\n",
    "    shared_counts = []\n",
    "\n",
    "    # Calculate shared flavor counts with other ingredients\n",
    "    for j in range(len(ingredients)):\n",
    "        if i != j:\n",
    "            ing2 = ingredients[j]\n",
    "            shared_count = len(set(ing1['flavors']).intersection(ing2['flavors']))\n",
    "            shared_counts.append((j, shared_count))\n",
    "\n",
    "    # Sort by shared flavor counts in descending order\n",
    "    shared_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Connect ing1 to the top 10 ingredients with the most shared flavors\n",
    "    for j, _ in shared_counts[:10]:\n",
    "        ing2 = ingredients[j]\n",
    "        graph.add_edge(ing1['name'], ing2['name'])\n",
    "\n",
    "\"\"\"\n",
    "All the parts of the graph are the same the only part which is different is the\n",
    "condition to have an edge between two nodes, and the weight of the nodes\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(100, 80))  # Adjust the figure size as desired (width, height)\n",
    "\n",
    "# Use spring layout with fixed seed for consistent layout\n",
    "pos = nx.spring_layout(graph, seed=42)\n",
    "\n",
    "# Draw nodes with correct colors based on categories\n",
    "node_colors = [category_colors[tuple(ingredient['category'])] for ingredient in ingredients]\n",
    "nx.draw_networkx_nodes(graph, pos, node_color=node_colors, node_size=2000, cmap='rainbow')\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(graph, pos)\n",
    "\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(graph, pos, font_size=20)\n",
    "\n",
    "# Draw category nodes\n",
    "for category, color in category_colors.items():\n",
    "    plt.text(0, 0, str(category), color=color, ha='center', fontsize=8)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#=========================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "#=========================================================\n",
    "# Generate random walks using Node2Vec\n",
    "node2vec = Node2Vec(graph, dimensions=64, walk_length=30, num_walks=200)\n",
    "model = node2vec.fit(window=10, min_count=1)\n",
    "\n",
    "# Retrieve node embeddings for available ingredients\n",
    "ingredient_embeddings = {}\n",
    "for ingredient_dict in ingredients:\n",
    "    ingredient_name = ingredient_dict['name']\n",
    "    if ingredient_name in model.wv:\n",
    "        embedding = model.wv[ingredient_name]\n",
    "        ingredient_embeddings[ingredient_name] = embedding\n",
    "    else:\n",
    "        continue\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "#=========================================================\n",
    "# Calculate different similarity matrices\n",
    "cosine_similarity_matrix = cosine_similarity(list(ingredient_embeddings.values()))\n",
    "euclidean_distance_matrix = euclidean_distances(list(ingredient_embeddings.values()))\n",
    "\n",
    "# Example: Find top 5 ingredients similar to \"Egg\" using different similarity measures\n",
    "target_ingredient = \"Egg\"\n",
    "target_embedding = ingredient_embeddings[target_ingredient]\n",
    "target_index = list(ingredient_embeddings.keys()).index(target_ingredient)\n",
    "\n",
    "# Cosine similarity\n",
    "similar_indices_cosine = cosine_similarity_matrix[target_index].argsort()[::-1][1:30]\n",
    "similar_ingredients_cosine = [list(ingredient_embeddings.keys())[i] for i in similar_indices_cosine]\n",
    "\n",
    "# Euclidean distance\n",
    "similar_indices_euclidean = euclidean_distance_matrix[target_index].argsort()[1:30]\n",
    "similar_ingredients_euclidean = [list(ingredient_embeddings.keys())[i] for i in similar_indices_euclidean]\n",
    "\n",
    "print(\"Ingredients similar to\", target_ingredient, \"using different similarity measures:\")\n",
    "print(\"Cosine similarity:\")\n",
    "for ingredient in similar_ingredients_cosine:\n",
    "    category = next((item['category'] for item in ingredients if item['name'] == ingredient), None)\n",
    "    if category and category[0] not in ['Meat', 'Seafood','Fish','Fungus']:\n",
    "        print(f\"Ingredient: {ingredient}, Category: {category}\")\n",
    "\n",
    "print(\"Euclidean distance:\")\n",
    "for ingredient in similar_ingredients_euclidean:\n",
    "    category = next((item['category'] for item in ingredients if item['name'] == ingredient), None)\n",
    "    if category and category[0] not in ['Meat', 'Seafood','Fungus','Fish']:\n",
    "        print(f\"Ingredient: {ingredient}, Category: {category}\")\n",
    "\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "#=========================================================\n",
    "# Perform dimensionality reduction on ingredient embeddings\n",
    "embeddings = np.array(list(ingredient_embeddings.values()))\n",
    "ingredient_names = list(ingredient_embeddings.keys())\n",
    "\n",
    "# Use t-SNE for dimensionality reduction\n",
    "tsne = TSNE(n_components=2)\n",
    "reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Get unique categories\n",
    "categories = set()\n",
    "for ingredient in ingredients:\n",
    "    categories.add(ingredient['category'][0])\n",
    "\n",
    "# Assign colors to categories\n",
    "category_colors = {}\n",
    "color_index = 0\n",
    "for category in categories:\n",
    "    category_colors[category] = f'C{color_index}'\n",
    "    color_index += 1\n",
    "\n",
    "# Plot the reduced embeddings without ingredient names and color nodes based on categories\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(len(ingredient_names)):\n",
    "    category = next((ingredient['category'][0] for ingredient in ingredients if ingredient['name'] == ingredient_names[i]), None)\n",
    "    if category:\n",
    "        plt.scatter(reduced_embeddings[i, 0], reduced_embeddings[i, 1], color=category_colors[category])\n",
    "\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.title(\"Ingredient Embeddings Visualization\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in my opinion is the best approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author notation\n",
    "In this modified code, each ingredient is connected to the top 10 ingredients that have the most shared molecules with it. The resulting graph will reflect these connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#=========================================================\n",
    "# Read the JSON file\n",
    "with open('C:/Users/ghaza/Downloads/integrated_data.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract ingredient names, molecules, and categories\n",
    "ingredients_data = data\n",
    "ingredients = []\n",
    "for ingredient in ingredients_data:\n",
    "    ingredient_dict = {\n",
    "        'name': ingredient['ingredients'],\n",
    "        'molecules': [],\n",
    "        'category': ingredient['category']  # Add the category information\n",
    "    }\n",
    "    \"\"\"\n",
    "    the same code\n",
    "    \"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "    for molecule in ingredient['molecules']:\n",
    "        ingredient_dict['molecules'].append(molecule['molecule'])\n",
    "    ingredients.append(ingredient_dict)\n",
    "\"\"\"\n",
    "changing one feature\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Create an empty graph\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Iterate over ingredients\n",
    "for i in range(len(ingredients)):\n",
    "    ing1 = ingredients[i]\n",
    "    shared_counts = []\n",
    "    \n",
    "    # Calculate shared molecule counts with other ingredients\n",
    "    for j in range(len(ingredients)):\n",
    "        if i != j:\n",
    "            ing2 = ingredients[j]\n",
    "            shared_count = len(set(ing1['molecules']).intersection(ing2['molecules']))\n",
    "            shared_counts.append((j, shared_count))\n",
    "    \n",
    "    # Sort by shared molecule counts in descending order\n",
    "    shared_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Connect ing1 to the top 10 ingredients with the most shared molecules\n",
    "    for j, _ in shared_counts[:10]:\n",
    "        ing2 = ingredients[j]\n",
    "        graph.add_edge(ing1['name'], ing2['name'])\n",
    "\"\"\"\n",
    "All the parts of the graph are the same the only part which is different is the\n",
    "condition to have an edge between two nodes, and the weight of the nodes\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Create a mapping of categories to colors\n",
    "category_colors = {}\n",
    "color_index = 0\n",
    "for ingredient in ingredients:\n",
    "    category = ingredient['category']\n",
    "    if isinstance(category, list):\n",
    "        category = tuple(category)\n",
    "    if category not in category_colors:\n",
    "        category_colors[category] = f'C{color_index}'\n",
    "        color_index += 1\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(100, 80))  # Adjust the figure size as desired (width, height)\n",
    "pos = nx.spring_layout(graph)  # Positions the nodes using the spring layout algorithm\n",
    "\n",
    "# Assign node colors based on categories\n",
    "node_colors = [category_colors[tuple(ingredient['category'])] for ingredient in ingredients]\n",
    "nx.draw_networkx_nodes(graph, pos, node_color=node_colors, node_size=2000, cmap='rainbow')\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(graph, pos)\n",
    "\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(graph, pos, font_size=20)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#=========================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "#=========================================================\n",
    "# Generate random walks using Node2Vec\n",
    "node2vec = Node2Vec(graph, dimensions=64, walk_length=30, num_walks=200)\n",
    "model = node2vec.fit(window=10, min_count=1)\n",
    "\n",
    "# Retrieve node embeddings for available ingredients\n",
    "ingredient_embeddings = {}\n",
    "for ingredient_dict in ingredients:\n",
    "    ingredient_name = ingredient_dict['name']\n",
    "    if ingredient_name in model.wv:\n",
    "        embedding = model.wv[ingredient_name]\n",
    "        ingredient_embeddings[ingredient_name] = embedding\n",
    "    else:\n",
    "        continue\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "#=========================================================\n",
    "# Calculate different similarity matrices\n",
    "cosine_similarity_matrix = cosine_similarity(list(ingredient_embeddings.values()))\n",
    "euclidean_distance_matrix = euclidean_distances(list(ingredient_embeddings.values()))\n",
    "\n",
    "# Example: Find top 5 ingredients similar to \"Egg\" using different similarity measures\n",
    "target_ingredient = \"Egg\"\n",
    "target_embedding = ingredient_embeddings[target_ingredient]\n",
    "target_index = list(ingredient_embeddings.keys()).index(target_ingredient)\n",
    "\n",
    "# Cosine similarity\n",
    "similar_indices_cosine = cosine_similarity_matrix[target_index].argsort()[::-1][1:30]\n",
    "similar_ingredients_cosine = [list(ingredient_embeddings.keys())[i] for i in similar_indices_cosine]\n",
    "\n",
    "# Euclidean distance\n",
    "similar_indices_euclidean = euclidean_distance_matrix[target_index].argsort()[1:30]\n",
    "similar_ingredients_euclidean = [list(ingredient_embeddings.keys())[i] for i in similar_indices_euclidean]\n",
    "\n",
    "print(\"Ingredients similar to\", target_ingredient, \"using different similarity measures:\")\n",
    "print(\"Cosine similarity:\")\n",
    "for ingredient in similar_ingredients_cosine:\n",
    "    category = next((item['category'] for item in ingredients if item['name'] == ingredient), None)\n",
    "    if category and category[0] not in ['Meat', 'Seafood','Fungus','Fish']:\n",
    "        print(f\"Ingredient: {ingredient}, Category: {category}\")\n",
    "\n",
    "print(\"Euclidean distance:\")\n",
    "for ingredient in similar_ingredients_euclidean:\n",
    "    category = next((item['category'] for item in ingredients if item['name'] == ingredient), None)\n",
    "    if category and category[0] not in ['Meat', 'Seafood','Fish','Fungus']:\n",
    "        print(f\"Ingredient: {ingredient}, Category: {category}\")\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#=========================================================\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perform dimensionality reduction on ingredient embeddings\n",
    "embeddings = np.array(list(ingredient_embeddings.values()))\n",
    "ingredient_names = list(ingredient_embeddings.keys())\n",
    "\n",
    "# Use t-SNE for dimensionality reduction\n",
    "tsne = TSNE(n_components=2)\n",
    "reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Get unique categories\n",
    "categories = set()\n",
    "for ingredient in ingredients:\n",
    "    categories.add(ingredient['category'][0])\n",
    "\n",
    "# Assign colors to categories\n",
    "category_colors = {}\n",
    "color_index = 0\n",
    "for category in categories:\n",
    "    category_colors[category] = f'C{color_index}'\n",
    "    color_index += 1\n",
    "\n",
    "# Plot the reduced embeddings without ingredient names and color nodes based on categories\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(len(ingredient_names)):\n",
    "    category = next((ingredient['category'][0] for ingredient in ingredients if ingredient['name'] == ingredient_names[i]), None)\n",
    "    if category:\n",
    "        plt.scatter(reduced_embeddings[i, 0], reduced_embeddings[i, 1], color=category_colors[category])\n",
    "\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.title(\"Ingredient Embeddings Visualization\")\n",
    "plt.show()\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author notation\n",
    "In this modified code, each ingredient is connected to the top 10 ingredients that have the most shared molecules with it. The resulting graph will reflect these connections and the count of shared molocules as considered as the weight of edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#=========================================================\n",
    "# Read the JSON file\n",
    "with open('C:/Users/ghaza/Downloads/integrated_data.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract ingredient names, molecules, and categories\n",
    "ingredients_data = data\n",
    "ingredients = []\n",
    "for ingredient in ingredients_data:\n",
    "    ingredient_dict = {\n",
    "        'name': ingredient['ingredients'],\n",
    "        'molecules': [],\n",
    "        'category': ingredient['category']  # Add the category information\n",
    "    }\n",
    "    \"\"\"\n",
    "    the same code\n",
    "    \"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "    for molecule in ingredient['molecules']:\n",
    "        ingredient_dict['molecules'].append(molecule['molecule'])\n",
    "    ingredients.append(ingredient_dict)\n",
    "\"\"\"\n",
    "changinf the featue\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Create an empty graph\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Iterate over ingredients\n",
    "for i in range(len(ingredients)):\n",
    "    ing1 = ingredients[i]\n",
    "    shared_counts = []\n",
    "    \n",
    "    # Calculate shared molecule counts with other ingredients\n",
    "    for j in range(len(ingredients)):\n",
    "        if i != j:\n",
    "            ing2 = ingredients[j]\n",
    "            shared_count = len(set(ing1['molecules']).intersection(ing2['molecules']))\n",
    "            shared_counts.append((j, shared_count))\n",
    "    \n",
    "    # Sort by shared molecule counts in descending order\n",
    "    shared_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Connect ing1 to the top 10 ingredients with the most shared molecules\n",
    "    for j, shared_count in shared_counts[:10]:\n",
    "        ing2 = ingredients[j]\n",
    "        if shared_count > 0:\n",
    "            graph.add_edge(ing1['name'], ing2['name'], weight=shared_count)\n",
    "\"\"\"\n",
    "All the parts of the graph are the same the only part which is different is the\n",
    "condition to have an edge between two nodes, and the weight of the nodes\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "# Create a mapping of categories to colors\n",
    "category_colors = {}\n",
    "color_index = 0\n",
    "for ingredient in ingredients:\n",
    "    category = ingredient['category']\n",
    "    if isinstance(category, list):\n",
    "        category = tuple(category)\n",
    "    if category not in category_colors:\n",
    "        category_colors[category] = f'C{color_index}'\n",
    "        color_index += 1\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#=========================================================\n",
    "\n",
    "#=========================================================\n",
    "plt.figure(figsize=(100, 80))  # Adjust the figure size as desired (width, height)\n",
    "pos = nx.spring_layout(graph)\n",
    "weights = nx.get_edge_attributes(graph, 'weight')\n",
    "\n",
    "# Assign node colors based on categories for all nodes in the graph\n",
    "node_colors = [category_colors[tuple(ingredient['category'])] for ingredient in ingredients if ingredient['name'] in graph.nodes]\n",
    "\n",
    "# Draw the graph with colored nodes\n",
    "nx.draw_networkx(graph, pos, with_labels=True, node_color=node_colors, node_size=100, font_size=20, cmap=plt.cm.rainbow)\n",
    "\n",
    "# Draw edge labels\n",
    "nx.draw_networkx_edge_labels(graph, pos, edge_labels=weights, font_size=10)\n",
    "\n",
    "plt.show()\n",
    "\"\"\"\n",
    "the same code, with sime slight differences\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "#=========================================================\n",
    "# Generate random walks using Node2Vec\n",
    "node2vec = Node2Vec(graph, dimensions=64, walk_length=30, num_walks=200)\n",
    "model = node2vec.fit(window=10, min_count=1)\n",
    "\n",
    "# Retrieve node embeddings for available ingredients\n",
    "ingredient_embeddings = {}\n",
    "for ingredient_dict in ingredients:\n",
    "    ingredient_name = ingredient_dict['name']\n",
    "    try:\n",
    "        embedding = model.wv[ingredient_name]\n",
    "        ingredient_embeddings[ingredient_name] = embedding\n",
    "    except KeyError:\n",
    "        continue\n",
    "\"\"\"\n",
    "the same code, I believe she accidentally added a try except loop here!!!!\n",
    "is quite better structure than privious one though.\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "#=========================================================\n",
    "# Calculate different similarity matrices\n",
    "cosine_similarity_matrix = cosine_similarity(list(ingredient_embeddings.values()))\n",
    "euclidean_distance_matrix = euclidean_distances(list(ingredient_embeddings.values()))\n",
    "\n",
    "# Example: Find top 5 ingredients similar to \"Egg\" using different similarity measures\n",
    "target_ingredient = \"Egg\"\n",
    "target_embedding = ingredient_embeddings[target_ingredient]\n",
    "target_index = list(ingredient_embeddings.keys()).index(target_ingredient)\n",
    "\n",
    "# Cosine similarity\n",
    "similar_indices_cosine = cosine_similarity_matrix[target_index].argsort()[::-1][1:30]\n",
    "similar_ingredients_cosine = [list(ingredient_embeddings.keys())[i] for i in similar_indices_cosine]\n",
    "\n",
    "# Euclidean distance\n",
    "similar_indices_euclidean = euclidean_distance_matrix[target_index].argsort()[1:30]\n",
    "similar_ingredients_euclidean = [list(ingredient_embeddings.keys())[i] for i in similar_indices_euclidean]\n",
    "\n",
    "print(\"Ingredients similar to\", target_ingredient, \"using different similarity measures:\")\n",
    "print(\"Cosine similarity:\")\n",
    "for ingredient in similar_ingredients_cosine:\n",
    "    category = next((item['category'] for item in ingredients if item['name'] == ingredient), None)\n",
    "    if category and category[0] not in ['Meat', 'Seafood','Fish','Fungus']:\n",
    "        print(f\"Ingredient: {ingredient}, Category: {category}\")\n",
    "\n",
    "print(\"Euclidean distance:\")\n",
    "for ingredient in similar_ingredients_euclidean:\n",
    "    category = next((item['category'] for item in ingredients if item['name'] == ingredient), None)\n",
    "    if category and category[0] not in ['Meat','Fish', 'Seafood','Fungus']:\n",
    "        print(f\"Ingredient: {ingredient}, Category: {category}\")\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "#=========================================================\n",
    "# Calculate different similarity matrices\n",
    "cosine_similarity_matrix = cosine_similarity(list(ingredient_embeddings.values()))\n",
    "euclidean_distance_matrix = euclidean_distances(list(ingredient_embeddings.values()))\n",
    "\n",
    "# Example: Find top 5 ingredients similar to \"Egg\" using different similarity measures\n",
    "target_ingredient = \"Egg\"\n",
    "target_embedding = ingredient_embeddings[target_ingredient]\n",
    "target_index = list(ingredient_embeddings.keys()).index(target_ingredient)\n",
    "\n",
    "# Cosine similarity\n",
    "similar_indices_cosine = cosine_similarity_matrix[target_index].argsort()[::-1][1:30]\n",
    "similar_ingredients_cosine = [list(ingredient_embeddings.keys())[i] for i in similar_indices_cosine]\n",
    "similar_ingredients_found_cosine = []\n",
    "\n",
    "# Euclidean distance\n",
    "similar_indices_euclidean = euclidean_distance_matrix[target_index].argsort()[1:30]\n",
    "similar_ingredients_euclidean = [list(ingredient_embeddings.keys())[i] for i in similar_indices_euclidean]\n",
    "similar_ingredients_found_euclidean = []\n",
    "\n",
    "print(\"Ingredients similar to\", target_ingredient, \"using different similarity measures:\")\n",
    "print(\"Cosine similarity:\")\n",
    "for ingredient in similar_ingredients_cosine:\n",
    "    category = next((item['category'] for item in ingredients if item['name'] == ingredient), None)\n",
    "    if category and category[0] not in ['Meat', 'Seafood', 'Fish', 'Fungus']:\n",
    "        print(f\"Ingredient: {ingredient}, Category: {category}\")\n",
    "        similar_ingredients_found_cosine.append(ingredient)\n",
    "\n",
    "print(\"Euclidean distance:\")\n",
    "for ingredient in similar_ingredients_euclidean:\n",
    "    category = next((item['category'] for item in ingredients if item['name'] == ingredient), None)\n",
    "    if category and category[0] not in ['Meat', 'Fish', 'Seafood', 'Fungus']:\n",
    "        print(f\"Ingredient: {ingredient}, Category: {category}\")\n",
    "        similar_ingredients_found_euclidean.append(ingredient)\n",
    "\n",
    "print(\"Ingredients similar to\", target_ingredient, \"found using cosine similarity:\")\n",
    "print(similar_ingredients_found_cosine)\n",
    "\n",
    "print(\"Ingredients similar to\", target_ingredient, \"found using euclidean distance:\")\n",
    "print(similar_ingredients_found_euclidean)\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================================\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perform dimensionality reduction on ingredient embeddings\n",
    "embeddings = np.array(list(ingredient_embeddings.values()))\n",
    "ingredient_names = list(ingredient_embeddings.keys())\n",
    "\n",
    "# Use t-SNE for dimensionality reduction\n",
    "tsne = TSNE(n_components=2)\n",
    "reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Get unique categories\n",
    "categories = set()\n",
    "for ingredient in ingredients:\n",
    "    categories.add(ingredient['category'][0])\n",
    "\n",
    "# Assign colors to categories\n",
    "category_colors = {}\n",
    "color_index = 0\n",
    "for category in categories:\n",
    "    category_colors[category] = f'C{color_index}'\n",
    "    color_index += 1\n",
    "\n",
    "# Plot the reduced embeddings without ingredient names and color nodes based on categories\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(len(ingredient_names)):\n",
    "    category = next((ingredient['category'][0] for ingredient in ingredients if ingredient['name'] == ingredient_names[i]), None)\n",
    "    if category:\n",
    "        plt.scatter(reduced_embeddings[i, 0], reduced_embeddings[i, 1], color=category_colors[category])\n",
    "\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.title(\"Ingredient Embeddings Visualization\")\n",
    "plt.show()\n",
    "\"\"\"\n",
    "the same code\n",
    "\"\"\"\n",
    "#========================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author notation\n",
    "To create an AI-powered tool that recommends egg replacements in bakery recipes, you can follow these steps:\n",
    "\n",
    "Data Collection: Gather a dataset of bakery recipes along with their ingredients and instructions. You can obtain recipe data from various online sources or use existing recipe datasets available.\n",
    "\n",
    "Preprocess the Data: Clean and preprocess the recipe data to remove any irrelevant information and standardize the ingredient names. You can use techniques like tokenization, lowercasing, and removing punctuation to prepare the data for further processing.\n",
    "\n",
    "Build Ingredient Embeddings: Train or load a pre-trained word embedding model (such as Word2Vec or GloVe) using a large corpus of text data. Map each ingredient to its corresponding word embedding vector. This step captures the semantic relationships between ingredients.\n",
    "\n",
    "Implement Egg Replacement Logic: Write a function or algorithm that takes a recipe as input and identifies the presence of eggs. If eggs are found, use the ingredient embeddings to recommend suitable replacements based on similarity measures like cosine similarity or Euclidean distance. The closest ingredient embeddings can be considered as potential replacements.\n",
    "\n",
    "Deploy the AI Tool: Create a user interface or API to interact with the AI-powered tool. Users can input a bakery recipe, and the tool will provide recommendations for egg replacements based on the implemented logic. The tool can display the recommended replacements and their corresponding similarity scores.\n",
    "\n",
    "Here's a code snippet to give you an idea of how to implement the egg replacement logic:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import numpy as np\n",
    "\n",
    "def recommend_egg_replacement(recipe, ingredient_embeddings, threshold=0.7):\n",
    "    # Check if the recipe contains eggs\n",
    "    if 'egg' not in recipe.lower():\n",
    "        return \"No egg replacements needed.\"\n",
    "\n",
    "    # Get the embedding for the 'egg' ingredient\n",
    "    egg_embedding = ingredient_embeddings['egg']\n",
    "\n",
    "    # Calculate similarity distances between the 'egg' embedding and other ingredients\n",
    "    distances = cosine_distances([egg_embedding], list(ingredient_embeddings.values()))\n",
    "\n",
    "    # Find ingredients with similarity above the threshold\n",
    "    replacements = []\n",
    "    for i, distance in enumerate(distances[0]):\n",
    "        if distance < threshold:\n",
    "            replacements.append(list(ingredient_embeddings.keys())[i])\n",
    "\n",
    "    if len(replacements) == 0:\n",
    "        return \"No suitable replacements found.\"\n",
    "    else:\n",
    "        return replacements\n",
    "\n",
    "# Example usage\n",
    "recipe = \"Classic chocolate chip cookies with eggs and butter\"\n",
    "replacements = recommend_egg_replacement(recipe, ingredient_embeddings, threshold=0.7)\n",
    "print(\"Recommended egg replacements:\", replacements)\n",
    "Please note that the above code assumes you have already obtained the ingredient embeddings and stored them in the ingredient_embeddings dictionary. The threshold parameter is used to control the similarity threshold for considering ingredient replacements.\n",
    "\n",
    "Remember to adapt the code to your specific dataset and requirements, and ensure that you have the necessary libraries installed (e.g., scikit-learn for cosine_distances)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Points\n",
    "In this part the author tried to make a response based on chat-gpt. She made a of gradient that can be used instead of egg and put them as an input into chat-gpt, then extract the answer from the mentioned bot. The last piece of the program is the most complete one. I will write some comments on that part, and erase rest of it to avoid confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFunctionality of Apple sauce as an egg replacement in bakery:\u001b[0m\n",
      "Apple sauce is a commonly used egg replacement in vegan baking as it can help bind ingredients together and add moisture to the recipe. Here are some ways in which apple sauce can be used in place of eggs:\n",
      "\n",
      "1. Binding: Applesauce can help bind ingredients together just like eggs. It works well in recipes that require one or two eggs. About 1/4 cup of applesauce can replace one egg in a recipe.\n",
      "\n",
      "2. Moisture: Applesauce can add moisture to the recipe, which is crucial in baked goods. Moisture helps to keep the baked goods moist and tender. This is especially important in recipes that require a lot of dry ingredients like flour. \n",
      "\n",
      "3. Flavor: Applesauce adds a slightly sweet and fruity flavor to baked goods. This can work well in recipes like muffins, cakes, and quick breads. \n",
      "\n",
      "It is important to note that using applesauce may not work in all recipes. It is best to experiment with the amount of applesauce used in the recipe and adjust the baking time accordingly.\n",
      "\u001b[32mFunctionality of Peanut butter as an egg replacement in bakery:\u001b[0m\n",
      "Peanut butter can be used as an egg replacement in bakery due to its binding and moisture-retaining properties. It is high in protein and contains natural oils, making it an excellent substitute for eggs in recipes that require binding agents.\n",
      "\n",
      "In recipes such as cakes, muffins, and cookies, peanut butter can be used as a replacement for eggs. Typically, 1/4 cup of peanut butter can replace one egg. Peanut butter can also add a unique flavor and texture to baked goods.\n",
      "\n",
      "However, it is important to note that using peanut butter as an egg replacement may alter the final taste and texture of the baked goods. It may also not work well in recipes that require a light and airy texture, such as angel food cake.\n",
      "\n",
      "Overall, peanut butter can be a suitable egg replacement in bakery, but it is important to test it out in small batches and adjust the recipe accordingly.\n",
      "\u001b[32mFunctionality of Buttermilk as an egg replacement in bakery:\u001b[0m\n",
      "Buttermilk can be used as an egg replacement in bakery for several reasons. Here are some functionalities of buttermilk as an egg replacement:\n",
      "\n",
      "1. Moisture: Buttermilk is a great source of moisture, which makes it an excellent substitute for eggs in baked goods. It can provide the necessary moisture to the batter or dough, resulting in a moist and tender texture.\n",
      "\n",
      "2. Binding: Eggs are often used in baking as a binding agent. Buttermilk can also provide this function as it contains proteins that can bind the ingredients together.\n",
      "\n",
      "3. Leavening: Eggs are also used as a leavening agent in some baked goods. Buttermilk can also act as a leavening agent due to its acidic nature. It can activate baking powder or baking soda, resulting in a rise in the dough or batter.\n",
      "\n",
      "4. Flavor: Buttermilk has a tangy flavor that can enhance the taste of baked goods. It can add a subtle sourness that complements sweet recipes.\n",
      "\n",
      "Overall, buttermilk can be a great substitute for eggs in bakery, especially in recipes that require moisture, binding, leavening, and flavor. It is a versatile ingredient that can be used in various baked goods, such as cakes, muffins, and pancakes.\n",
      "\u001b[32mFunctionality of yogurt as an egg replacement in bakery:\u001b[0m\n",
      "Yogurt can be used as an egg replacement in bakery recipes because it helps to bind ingredients together and provides moisture and acidity. Here are some tips and guidelines for using yogurt as an egg substitute:\n",
      "\n",
      "- Use 1/4 cup of plain yogurt per egg in the recipe.\n",
      "- Greek yogurt works well because it is thicker and creamier than regular yogurt.\n",
      "- If the recipe calls for both eggs and oil, you can replace both with yogurt to make it even healthier.\n",
      "- Yogurt can be used in most baked goods, such as cakes, muffins, and cookies.\n",
      "- Be careful not to overmix the batter when using yogurt, as it can make the baked goods tough.\n",
      "- Yogurt adds a tangy flavor to baked goods, so it may not be suitable for all recipes.\n",
      "- For best results, use full-fat yogurt, as low-fat or non-fat yogurt may affect the texture and consistency of the baked goods.\n",
      "\n",
      "Overall, yogurt is a versatile egg substitute that can be used in a variety of baked goods to make them healthier and more flavorful.\n",
      "\u001b[32mFunctionality of Coconut as an egg replacement in bakery:\u001b[0m\n",
      "Coconut can be used as an egg replacement in bakery products due to its binding and moistening properties. Here are some ways in which coconut can replace eggs in baking:\n",
      "\n",
      "1. Coconut milk: Coconut milk can be used as a replacement for eggs in most baked goods. It adds moisture and richness to the recipe, and also helps to bind the ingredients together.\n",
      "\n",
      "2. Coconut yogurt: Coconut yogurt can be used as an egg substitute in recipes that require a tangy flavor, such as muffins or cakes. It also adds moisture and helps to bind the ingredients together.\n",
      "\n",
      "3. Coconut oil: Coconut oil can be used as an egg replacement in recipes that require a certain level of fat. It adds moisture and helps to bind the ingredients together, while also giving a subtle coconut flavor to the baked goods.\n",
      "\n",
      "4. Coconut flour: Coconut flour can be used as a replacement for eggs in recipes that require a binding agent. It is high in fiber and adds moisture to the recipe, while also helping to bind the ingredients together.\n",
      "\n",
      "Overall, coconut is a versatile ingredient that can be used in a variety of ways to replace eggs in baking. It adds moisture, richness, and binding properties to the recipe, while also providing a subtle coconut flavor.\n",
      "\u001b[32mFunctionality of Soybeans as an egg replacement in bakery:\u001b[0m\n",
      "Soybeans can be used as an egg replacement in bakery due to their ability to provide similar binding and emulsifying properties as eggs. Here are some of the functionalities of soybeans as an egg replacement in bakery:\n",
      "\n",
      "1. Binding: Soybeans contain proteins that can bind ingredients together, similar to the way eggs do. This helps to hold the structure of baked goods, such as cakes, muffins, and cookies.\n",
      "\n",
      "2. Emulsifying: Soybeans contain lecithin, a natural emulsifier that helps to blend ingredients that normally don't mix well, such as oil and water. This gives baked goods a smooth texture and prevents them from separating.\n",
      "\n",
      "3. Moisture retention: Soybeans can help to retain moisture in baked goods, which can be especially important in cakes and muffins. This can help to prevent them from becoming dry and crumbly.\n",
      "\n",
      "4. Nutrient density: Soybeans are rich in nutrients, including protein, fiber, and vitamins. Adding soybeans to baked goods can increase their nutritional value and make them a healthier option.\n",
      "\n",
      "Overall, soybeans can be an effective egg replacement in bakery, providing similar functionalities and nutritional benefits. However, it's important to note that soybeans may not be suitable for those with soy allergies or sensitivities.\n",
      "\u001b[32mFunctionality of kidney beans as an egg replacement in bakery:\u001b[0m\n",
      "As an AI language model, I am not capable of consuming food, however, I can provide you with information about the functionality of kidney beans as an egg replacement in bakery.\n",
      "\n",
      "Kidney beans can be used as an egg replacement in bakery due to their high protein and starch content. When the beans are pureed, they create a thick and creamy consistency that can mimic the binding properties of eggs. This makes kidney beans a suitable replacement for eggs in baked goods such as cakes, cookies, and muffins.\n",
      "\n",
      "In addition to their binding properties, kidney beans also provide moisture to baked goods, which is essential for creating a tender and moist texture. They also add a slightly nutty flavor to the baked goods, which can enhance the overall taste.\n",
      "\n",
      "However, it is important to note that kidney beans should be thoroughly cooked and pureed before using them as an egg replacement. Raw kidney beans contain a toxin called lectin, which can cause digestive issues if consumed in large quantities. So, make sure to cook the beans properly before using them in your recipes.\n",
      "\u001b[32mFunctionality of Ground Flaxseeds as an egg replacement in bakery:\u001b[0m\n",
      "Ground flaxseeds can be used as an egg replacement in bakery recipes because they contain a high amount of soluble fiber, which when mixed with water, forms a gel-like substance that can mimic the binding properties of eggs. The gel-like substance can help hold the ingredients of a recipe together, making it a suitable replacement for eggs in baked goods such as cakes, muffins, and bread. \n",
      "\n",
      "To use ground flaxseeds as an egg replacement, mix 1 tablespoon of ground flaxseeds with 3 tablespoons of water and let it sit for a few minutes until it thickens. This mixture can then be added to the recipe in place of one egg. It is important to note that the texture and taste of the final product may differ slightly when using ground flaxseeds as an egg replacement, but it is a great option for those who are vegan, allergic to eggs, or looking to reduce their cholesterol intake.\n",
      "\u001b[32mFunctionality of cauliflower as an egg replacement in bakery:\u001b[0m\n",
      "Cauliflower can be used as an egg replacement in bakery products due to its unique texture and taste. Here are some ways cauliflower can be used as an egg replacement:\n",
      "\n",
      "1. Pureed cauliflower: Pureed cauliflower can be used as a substitute for eggs in baked goods like cakes, cookies, and muffins. Simply boil or steam cauliflower until it is soft, then blend it into a smooth puree. Use 1/4 cup of pureed cauliflower for each egg in the recipe.\n",
      "\n",
      "2. Cauliflower rice: Cauliflower rice can also be used as a substitute for eggs in baked goods. Simply grate the cauliflower into small pieces and use 1/4 cup of cauliflower rice for each egg in the recipe.\n",
      "\n",
      "3. Cauliflower yogurt: Cauliflower yogurt is a vegan alternative to regular yogurt that can be used as an egg replacement in baking. Simply blend steamed cauliflower with vegan yogurt until smooth. Use 1/4 cup of cauliflower yogurt for each egg in the recipe.\n",
      "\n",
      "Overall, cauliflower is a versatile ingredient that can be used to replace eggs in a variety of baked goods. It is low in calories, high in fiber, and packed with nutrients, making it a healthy alternative to eggs.\n",
      "\u001b[32mFunctionality of beans as an egg replacement in bakery:\u001b[0m\n",
      "Beans can be used as an egg replacement in bakery products due to their binding and emulsifying properties. When pureed, beans can provide the same consistency and texture as eggs in baked goods. Here are some ways beans can be used as an egg replacement:\n",
      "\n",
      "1. Pureed beans: Pureed beans can be used as a 1:1 substitute for eggs in most baked goods. Simply puree the beans with a little water until smooth and use in place of eggs.\n",
      "\n",
      "2. Bean flour: Bean flour can be used in place of regular flour in some baked goods. It can provide the same binding properties as eggs and add a nutty flavor to the baked goods.\n",
      "\n",
      "3. Aquafaba: Aquafaba is the liquid found in canned chickpeas and other beans. It can be whipped like egg whites and used in place of eggs in meringues, macarons, and other desserts.\n",
      "\n",
      "Overall, beans can be a great egg replacement in bakery products for those who are vegan or have an egg allergy. They are also a healthier alternative to eggs as they are low in cholesterol and high in protein.\n",
      "\u001b[32mFunctionality of Chickpeas as an egg replacement in bakery:\u001b[0m\n",
      "Chickpeas can be used as an egg replacement in bakery due to their unique properties. Here are some ways chickpeas can be used as an egg replacement:\n",
      "\n",
      "1. Aquafaba: The liquid from a can of chickpeas, also known as aquafaba, can be used as an egg replacement in many baked goods such as meringues, macarons, and cakes. It can be whipped into a foam that mimics the texture of egg whites.\n",
      "\n",
      "2. Pureed chickpeas: Chickpeas can be pureed and used as a binder in baked goods such as cookies, brownies, and cakes. They add moisture and give a slightly nutty flavor to the baked goods.\n",
      "\n",
      "3. Chickpea flour: Chickpea flour can be used as a direct replacement for eggs in some recipes. It works well in savory baked goods such as quiches, frittatas, and savory bread.\n",
      "\n",
      "Chickpeas are a great egg replacement for those who are vegan or have egg allergies. They are also a great source of protein, fiber, and other nutrients.\n",
      "\u001b[32mFunctionality of Milk as an egg replacement in bakery:\u001b[0m\n",
      "Milk can be used as an egg replacement in some bakery recipes, although it may not work in all recipes.\n",
      "\n",
      "Here are some ways milk can be used as an egg replacement:\n",
      "\n",
      "1. Binding: Milk can help bind the ingredients together in a recipe, much like eggs do. This can work well in recipes like cakes, muffins, and quick breads.\n",
      "\n",
      "2. Moisture: Milk can add moisture to a recipe, which is important in baked goods like cakes and cookies. This can help prevent the baked goods from becoming dry and crumbly.\n",
      "\n",
      "3. Leavening: Milk can help leaven baked goods, especially when combined with vinegar or lemon juice. This can work well in recipes like pancakes and waffles.\n",
      "\n",
      "To use milk as an egg replacement, you can generally substitute 1/4 cup of milk for each egg called for in the recipe. You may need to adjust the other ingredients in the recipe to ensure the proper texture and consistency.\n",
      "\u001b[32mFunctionality of lima beans as an egg replacement in bakery:\u001b[0m\n",
      "Lima beans can be used as an egg replacement in bakery due to their ability to provide structure, moisture, and binding properties. When pureed, lima beans can act as a substitute for eggs in various baked goods such as cakes, muffins, and cookies.\n",
      "\n",
      "The protein in lima beans creates a stable structure, similar to that of eggs, which helps to hold the baked goods together. Additionally, the starch in lima beans provides moisture and helps to keep the baked goods from becoming dry. The binding properties of lima beans also help to hold the ingredients together, creating a cohesive batter or dough.\n",
      "\n",
      "Overall, using lima beans as an egg replacement in bakery can be a healthy and sustainable choice for those who are vegan or have egg allergies.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "from colorama import Fore, Style\n",
    "#=========================================================\n",
    "API_KEY = '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'\n",
    "url = 'https://api.openai.com/v1/chat/completions'\n",
    "header = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {API_KEY}'\n",
    "}\n",
    "\n",
    "ingredients = [\"Apple sauce\", \"Peanut butter\", \"Buttermilk\", \"yogurt\", \"Coconut\", \"Soybeans\",\"kidney beans\",\"Ground Flaxseeds\", \"cauliflower\", \"beans\", \"Chickpeas\",\"Milk\",\"lima beans\"]\n",
    "for ingredient in ingredients:\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": f\"functionality of {ingredient} as an egg replacement in bakery!\"}],\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=header, data=json.dumps(data))\n",
    "    response_json = response.json()\n",
    "\n",
    "    # Extracting the generated answer from the API response\n",
    "    answer = response_json['choices'][0]['message']['content']\n",
    "\n",
    "    # Print the answer with ingredient name in color\n",
    "    colored_functionality = Fore.GREEN + f\"Functionality of {ingredient} as an egg replacement in bakery:\" + Style.RESET_ALL\n",
    "    print(colored_functionality)\n",
    "    print(answer)\n",
    "\n",
    "    # Wait for 30 seconds before making another API request\n",
    "    time.sleep(30)\n",
    "\n",
    "    \"\"\"\n",
    "    This pieace of code can be transfered into a function, the name of the function can be\n",
    "    'testing_pipeline'. the ingredients, API_key and url can be put in the function as its\n",
    "    input and the answer can be the output of the function. \n",
    "    \"\"\"\n",
    "#=========================================================\n",
    "\"\"\"\n",
    "In general, it can be quite practical to have a 'main()' function to run all the mentioned\n",
    "function inside it. Then, this function can be run through\n",
    "if __name__() == '__main__':\n",
    "    main(input values) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned multiple times during the code review, This code have a vital need of structure. One of the structure that can be used for this part of the pipeline is as follows. Many other implementations can be used, but I found the following more organized and maintaimable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example structure\n",
    "class IntegratedData():\n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "    def making_file_paths_list():\n",
    "        pass\n",
    "\n",
    "    def making_integrated_data():\n",
    "        pass\n",
    "\n",
    "    def saving_file():\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def config():\n",
    "        pass\n",
    "\n",
    "class Graph():\n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "    def making_graph():\n",
    "        pass\n",
    "\n",
    "    def drawing_graph():\n",
    "        pass\n",
    "\n",
    "class Embedding():\n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "    def making_embedding_models():\n",
    "        pass\n",
    "    \n",
    "    def making_embedding_dict():\n",
    "        pass\n",
    "\n",
    "class SimilarityMetrices(Embedding):\n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "    def most_similar_eucledian():\n",
    "        pass\n",
    "\n",
    "    def most_similar_cosine():\n",
    "        pass\n",
    "\n",
    "class dimensionalityReduction():\n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "    def t_sne():\n",
    "        pass\n",
    "\n",
    "    def drawing_reduced_dimensions():\n",
    "        pass\n",
    "\n",
    "class TestIngradients():\n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "    def egg():\n",
    "        pass\n",
    "\n",
    "if __name__() == '__main__':\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
