{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook\n",
    "In this notebook, I will test all the functions and classes that I am making in the main program to see the outcome of them dynamically.\n",
    "\n",
    "## Evaluate the DataDivider class\n",
    "in this part I will analyze the data and adjuct the DataDivider class for this assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the general libraries\n",
    "import yaml\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspired by https://fennaf.gitbook.io/bfvm22prog1/data-processing/configuration-files/yaml\n",
    "\n",
    "def configReader():\n",
    "    \"\"\"\n",
    "    explanation: This function open config,yaml file \n",
    "    and fetch the gonfigue file information\n",
    "    input: ...\n",
    "    output: configue file\n",
    "    \"\"\"\n",
    "    with open(\"config.yaml\", \"r\") as inputFile:\n",
    "        config = yaml.safe_load(inputFile)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sensor_00</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_06</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>sensor_08</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_43</th>\n",
       "      <th>sensor_44</th>\n",
       "      <th>sensor_45</th>\n",
       "      <th>sensor_46</th>\n",
       "      <th>sensor_47</th>\n",
       "      <th>sensor_48</th>\n",
       "      <th>sensor_49</th>\n",
       "      <th>sensor_50</th>\n",
       "      <th>sensor_51</th>\n",
       "      <th>machine_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-01 00:00:00</td>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>15.56713</td>\n",
       "      <td>...</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>243.0556</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-01 00:01:00</td>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>15.56713</td>\n",
       "      <td>...</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>243.0556</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-01 00:02:00</td>\n",
       "      <td>2.444734</td>\n",
       "      <td>47.35243</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.397570</td>\n",
       "      <td>638.8889</td>\n",
       "      <td>73.54598</td>\n",
       "      <td>13.32465</td>\n",
       "      <td>16.03733</td>\n",
       "      <td>15.61777</td>\n",
       "      <td>...</td>\n",
       "      <td>41.66666</td>\n",
       "      <td>39.351852</td>\n",
       "      <td>65.39352</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194443</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>67.12963</td>\n",
       "      <td>241.3194</td>\n",
       "      <td>203.7037</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-01 00:03:00</td>\n",
       "      <td>2.460474</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.1684</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>628.1250</td>\n",
       "      <td>76.98898</td>\n",
       "      <td>13.31742</td>\n",
       "      <td>16.24711</td>\n",
       "      <td>15.69734</td>\n",
       "      <td>...</td>\n",
       "      <td>40.88541</td>\n",
       "      <td>39.062500</td>\n",
       "      <td>64.81481</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>66.84028</td>\n",
       "      <td>240.4514</td>\n",
       "      <td>203.1250</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-01 00:04:00</td>\n",
       "      <td>2.445718</td>\n",
       "      <td>47.13541</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>636.4583</td>\n",
       "      <td>76.58897</td>\n",
       "      <td>13.35359</td>\n",
       "      <td>16.21094</td>\n",
       "      <td>15.69734</td>\n",
       "      <td>...</td>\n",
       "      <td>41.40625</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>65.10416</td>\n",
       "      <td>51.79398</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>158.2755</td>\n",
       "      <td>66.55093</td>\n",
       "      <td>242.1875</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  sensor_00  sensor_01  sensor_02  sensor_03  sensor_04  \\\n",
       "0  2018-04-01 00:00:00   2.465394   47.09201    53.2118  46.310760   634.3750   \n",
       "1  2018-04-01 00:01:00   2.465394   47.09201    53.2118  46.310760   634.3750   \n",
       "2  2018-04-01 00:02:00   2.444734   47.35243    53.2118  46.397570   638.8889   \n",
       "3  2018-04-01 00:03:00   2.460474   47.09201    53.1684  46.397568   628.1250   \n",
       "4  2018-04-01 00:04:00   2.445718   47.13541    53.2118  46.397568   636.4583   \n",
       "\n",
       "   sensor_05  sensor_06  sensor_07  sensor_08  ...  sensor_43  sensor_44  \\\n",
       "0   76.45975   13.41146   16.13136   15.56713  ...   41.92708  39.641200   \n",
       "1   76.45975   13.41146   16.13136   15.56713  ...   41.92708  39.641200   \n",
       "2   73.54598   13.32465   16.03733   15.61777  ...   41.66666  39.351852   \n",
       "3   76.98898   13.31742   16.24711   15.69734  ...   40.88541  39.062500   \n",
       "4   76.58897   13.35359   16.21094   15.69734  ...   41.40625  38.773150   \n",
       "\n",
       "   sensor_45  sensor_46  sensor_47  sensor_48  sensor_49  sensor_50  \\\n",
       "0   65.68287   50.92593  38.194440   157.9861   67.70834   243.0556   \n",
       "1   65.68287   50.92593  38.194440   157.9861   67.70834   243.0556   \n",
       "2   65.39352   51.21528  38.194443   155.9606   67.12963   241.3194   \n",
       "3   64.81481   51.21528  38.194440   155.9606   66.84028   240.4514   \n",
       "4   65.10416   51.79398  38.773150   158.2755   66.55093   242.1875   \n",
       "\n",
       "   sensor_51  machine_status  \n",
       "0   201.3889          NORMAL  \n",
       "1   201.3889          NORMAL  \n",
       "2   203.7037          NORMAL  \n",
       "3   203.1250          NORMAL  \n",
       "4   201.3889          NORMAL  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataframe_maker(config):\n",
    "    file_directory, file_name = config.values()\n",
    "    os.chdir(file_directory)\n",
    "    df = pd.read_csv(file_name).drop('Unnamed: 0', axis=1)\n",
    "    return df\n",
    "df = dataframe_maker(configReader())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_00</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_06</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>sensor_08</th>\n",
       "      <th>sensor_09</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_43</th>\n",
       "      <th>sensor_44</th>\n",
       "      <th>sensor_45</th>\n",
       "      <th>sensor_46</th>\n",
       "      <th>sensor_47</th>\n",
       "      <th>sensor_48</th>\n",
       "      <th>sensor_49</th>\n",
       "      <th>sensor_50</th>\n",
       "      <th>sensor_51</th>\n",
       "      <th>machine_status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>15.56713</td>\n",
       "      <td>15.05353</td>\n",
       "      <td>...</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>243.0556</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:01:00</th>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>15.56713</td>\n",
       "      <td>15.05353</td>\n",
       "      <td>...</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>243.0556</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:02:00</th>\n",
       "      <td>2.444734</td>\n",
       "      <td>47.35243</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.397570</td>\n",
       "      <td>638.8889</td>\n",
       "      <td>73.54598</td>\n",
       "      <td>13.32465</td>\n",
       "      <td>16.03733</td>\n",
       "      <td>15.61777</td>\n",
       "      <td>15.01013</td>\n",
       "      <td>...</td>\n",
       "      <td>41.66666</td>\n",
       "      <td>39.351852</td>\n",
       "      <td>65.39352</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194443</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>67.12963</td>\n",
       "      <td>241.3194</td>\n",
       "      <td>203.7037</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:03:00</th>\n",
       "      <td>2.460474</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.1684</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>628.1250</td>\n",
       "      <td>76.98898</td>\n",
       "      <td>13.31742</td>\n",
       "      <td>16.24711</td>\n",
       "      <td>15.69734</td>\n",
       "      <td>15.08247</td>\n",
       "      <td>...</td>\n",
       "      <td>40.88541</td>\n",
       "      <td>39.062500</td>\n",
       "      <td>64.81481</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>66.84028</td>\n",
       "      <td>240.4514</td>\n",
       "      <td>203.1250</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:04:00</th>\n",
       "      <td>2.445718</td>\n",
       "      <td>47.13541</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>636.4583</td>\n",
       "      <td>76.58897</td>\n",
       "      <td>13.35359</td>\n",
       "      <td>16.21094</td>\n",
       "      <td>15.69734</td>\n",
       "      <td>15.08247</td>\n",
       "      <td>...</td>\n",
       "      <td>41.40625</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>65.10416</td>\n",
       "      <td>51.79398</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>158.2755</td>\n",
       "      <td>66.55093</td>\n",
       "      <td>242.1875</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sensor_00  sensor_01  sensor_02  sensor_03  sensor_04  \\\n",
       "timestamp                                                                    \n",
       "2018-04-01 00:00:00   2.465394   47.09201    53.2118  46.310760   634.3750   \n",
       "2018-04-01 00:01:00   2.465394   47.09201    53.2118  46.310760   634.3750   \n",
       "2018-04-01 00:02:00   2.444734   47.35243    53.2118  46.397570   638.8889   \n",
       "2018-04-01 00:03:00   2.460474   47.09201    53.1684  46.397568   628.1250   \n",
       "2018-04-01 00:04:00   2.445718   47.13541    53.2118  46.397568   636.4583   \n",
       "\n",
       "                     sensor_05  sensor_06  sensor_07  sensor_08  sensor_09  \\\n",
       "timestamp                                                                    \n",
       "2018-04-01 00:00:00   76.45975   13.41146   16.13136   15.56713   15.05353   \n",
       "2018-04-01 00:01:00   76.45975   13.41146   16.13136   15.56713   15.05353   \n",
       "2018-04-01 00:02:00   73.54598   13.32465   16.03733   15.61777   15.01013   \n",
       "2018-04-01 00:03:00   76.98898   13.31742   16.24711   15.69734   15.08247   \n",
       "2018-04-01 00:04:00   76.58897   13.35359   16.21094   15.69734   15.08247   \n",
       "\n",
       "                     ...  sensor_43  sensor_44  sensor_45  sensor_46  \\\n",
       "timestamp            ...                                               \n",
       "2018-04-01 00:00:00  ...   41.92708  39.641200   65.68287   50.92593   \n",
       "2018-04-01 00:01:00  ...   41.92708  39.641200   65.68287   50.92593   \n",
       "2018-04-01 00:02:00  ...   41.66666  39.351852   65.39352   51.21528   \n",
       "2018-04-01 00:03:00  ...   40.88541  39.062500   64.81481   51.21528   \n",
       "2018-04-01 00:04:00  ...   41.40625  38.773150   65.10416   51.79398   \n",
       "\n",
       "                     sensor_47  sensor_48  sensor_49  sensor_50  sensor_51  \\\n",
       "timestamp                                                                    \n",
       "2018-04-01 00:00:00  38.194440   157.9861   67.70834   243.0556   201.3889   \n",
       "2018-04-01 00:01:00  38.194440   157.9861   67.70834   243.0556   201.3889   \n",
       "2018-04-01 00:02:00  38.194443   155.9606   67.12963   241.3194   203.7037   \n",
       "2018-04-01 00:03:00  38.194440   155.9606   66.84028   240.4514   203.1250   \n",
       "2018-04-01 00:04:00  38.773150   158.2755   66.55093   242.1875   201.3889   \n",
       "\n",
       "                     machine_status  \n",
       "timestamp                            \n",
       "2018-04-01 00:00:00          NORMAL  \n",
       "2018-04-01 00:01:00          NORMAL  \n",
       "2018-04-01 00:02:00          NORMAL  \n",
       "2018-04-01 00:03:00          NORMAL  \n",
       "2018-04-01 00:04:00          NORMAL  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('timestamp', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 220320 entries, 2018-04-01 00:00:00 to 2018-08-31 23:59:00\n",
      "Data columns (total 53 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   sensor_00       210112 non-null  float64\n",
      " 1   sensor_01       219951 non-null  float64\n",
      " 2   sensor_02       220301 non-null  float64\n",
      " 3   sensor_03       220301 non-null  float64\n",
      " 4   sensor_04       220301 non-null  float64\n",
      " 5   sensor_05       220301 non-null  float64\n",
      " 6   sensor_06       215522 non-null  float64\n",
      " 7   sensor_07       214869 non-null  float64\n",
      " 8   sensor_08       215213 non-null  float64\n",
      " 9   sensor_09       215725 non-null  float64\n",
      " 10  sensor_10       220301 non-null  float64\n",
      " 11  sensor_11       220301 non-null  float64\n",
      " 12  sensor_12       220301 non-null  float64\n",
      " 13  sensor_13       220301 non-null  float64\n",
      " 14  sensor_14       220299 non-null  float64\n",
      " 15  sensor_15       0 non-null       float64\n",
      " 16  sensor_16       220289 non-null  float64\n",
      " 17  sensor_17       220274 non-null  float64\n",
      " 18  sensor_18       220274 non-null  float64\n",
      " 19  sensor_19       220304 non-null  float64\n",
      " 20  sensor_20       220304 non-null  float64\n",
      " 21  sensor_21       220304 non-null  float64\n",
      " 22  sensor_22       220279 non-null  float64\n",
      " 23  sensor_23       220304 non-null  float64\n",
      " 24  sensor_24       220304 non-null  float64\n",
      " 25  sensor_25       220284 non-null  float64\n",
      " 26  sensor_26       220300 non-null  float64\n",
      " 27  sensor_27       220304 non-null  float64\n",
      " 28  sensor_28       220304 non-null  float64\n",
      " 29  sensor_29       220248 non-null  float64\n",
      " 30  sensor_30       220059 non-null  float64\n",
      " 31  sensor_31       220304 non-null  float64\n",
      " 32  sensor_32       220252 non-null  float64\n",
      " 33  sensor_33       220304 non-null  float64\n",
      " 34  sensor_34       220304 non-null  float64\n",
      " 35  sensor_35       220304 non-null  float64\n",
      " 36  sensor_36       220304 non-null  float64\n",
      " 37  sensor_37       220304 non-null  float64\n",
      " 38  sensor_38       220293 non-null  float64\n",
      " 39  sensor_39       220293 non-null  float64\n",
      " 40  sensor_40       220293 non-null  float64\n",
      " 41  sensor_41       220293 non-null  float64\n",
      " 42  sensor_42       220293 non-null  float64\n",
      " 43  sensor_43       220293 non-null  float64\n",
      " 44  sensor_44       220293 non-null  float64\n",
      " 45  sensor_45       220293 non-null  float64\n",
      " 46  sensor_46       220293 non-null  float64\n",
      " 47  sensor_47       220293 non-null  float64\n",
      " 48  sensor_48       220293 non-null  float64\n",
      " 49  sensor_49       220293 non-null  float64\n",
      " 50  sensor_50       143303 non-null  float64\n",
      " 51  sensor_51       204937 non-null  float64\n",
      " 52  machine_status  220320 non-null  object \n",
      "dtypes: float64(52), object(1)\n",
      "memory usage: 98.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# some information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-04-01 00:00:00', '2018-04-01 00:01:00',\n",
       "               '2018-04-01 00:02:00', '2018-04-01 00:03:00',\n",
       "               '2018-04-01 00:04:00', '2018-04-01 00:05:00',\n",
       "               '2018-04-01 00:06:00', '2018-04-01 00:07:00',\n",
       "               '2018-04-01 00:08:00', '2018-04-01 00:09:00',\n",
       "               ...\n",
       "               '2018-08-31 23:50:00', '2018-08-31 23:51:00',\n",
       "               '2018-08-31 23:52:00', '2018-08-31 23:53:00',\n",
       "               '2018-08-31 23:54:00', '2018-08-31 23:55:00',\n",
       "               '2018-08-31 23:56:00', '2018-08-31 23:57:00',\n",
       "               '2018-08-31 23:58:00', '2018-08-31 23:59:00'],\n",
       "              dtype='datetime64[ns]', name='timestamp', length=220320, freq=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the index of the dataset\n",
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset starts from April and ends at the end of August."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_divider(df, frequency='M'):\n",
    "\n",
    "    # Make a series of the range in which wants to divide the data\n",
    "    start_date = df.index.min()\n",
    "    end_date = df.index.max()\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='M')\n",
    "\n",
    "    # Slice around 60% of the dataset for training purpose\n",
    "    train_month_number = int(len(dates) * 0.6) - 1\n",
    "    df_train = df.loc[:dates[train_month_number]]\n",
    "\n",
    "    # add test datasets to the divided dataframe dictionary using dic comprehension\n",
    "    divided_df_dict = {f'df_test{number+1}': df.loc[dates[counter]:dates[counter+1]]\n",
    "            for number, counter in enumerate(range(train_month_number, len(dates) - 1, 1))}\n",
    "    \n",
    "    # add training data to the dictionary\n",
    "    divided_df_dict['df_train'] = df_train\n",
    "\n",
    "    return divided_df_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made the above function to divide the dataset into one train data (about 60% of the dataset), and divide rest of the dataset into a number od testing datasets. It can change dynamically based on the date range that is used as the input. Also, I made a version of this function to save the dataframes directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def dataframe_divider(self, division_range='M'):\n",
    "        \"\"\"\n",
    "        this method divide the dataset into definite number of \n",
    "        training and testing datasets, then save them in a determined path\n",
    "        \"\"\"\n",
    "        # change the directory\n",
    "        output_dir = self.config['output_path']\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Make a series of the range in which wants to divide the data\n",
    "        start_date = self.df.index.min()\n",
    "        end_date = self.df.index.max()\n",
    "        dates = pd.date_range(start=start_date, end=end_date, freq=division_range)\n",
    "\n",
    "        # Slice around 60% of the dataset for training purpose\n",
    "        train_month_number = int(len(dates) * 0.6) - 1\n",
    "        df_train = self.df.loc[:dates[train_month_number]]\n",
    "\n",
    "        # save the train dataset\n",
    "        df_train.to_csv(os.path.join(output_dir, 'df_train.csv'))\n",
    "\n",
    "        # save all the test sets\n",
    "        for number, counter in enumerate(range(train_month_number, len(dates) - 1, 1)):\n",
    "            df_test = self.df.loc[dates[counter]:dates[counter+1]]\n",
    "            df_test.to_csv(os.path.join(output_dir, f'df_test{number+1}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataDivider Class\n",
    "This is one version of the this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is another version of this class\n",
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class DataDivider():\n",
    "\n",
    "    def __init__(self, input_path):\n",
    "        self.config = self.config_reader(input_path)\n",
    "        self.df = self.dataframe_maker()\n",
    "        #self.output_dir = self.config['output_path']\n",
    "\n",
    "    def config_reader(self, input_path):\n",
    "        \"\"\"\n",
    "        explanation: This function open config,yaml file \n",
    "        and fetch the gonfigue file information\n",
    "        input: ...\n",
    "        output: configue file\n",
    "        \"\"\"\n",
    "        with open(input_path, \"r\", encoding=\"utf8\") as input_file:\n",
    "            config = yaml.safe_load(input_file)\n",
    "\n",
    "        return config\n",
    "\n",
    "    def dataframe_maker(self):\n",
    "        \"\"\"\n",
    "        make the main dataset based on the configuration file\n",
    "        \"\"\"\n",
    "        # make the dataframe\n",
    "        file_directory, file_name, _ = self.config.values()\n",
    "        os.chdir(file_directory)\n",
    "        df = pd.read_csv(file_name).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "        # change the type of the timestamp column\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "        # set timestamp column as the index\n",
    "        df.set_index('timestamp', inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def dataframe_divider(self, division_range='M'):\n",
    "        \"\"\"\n",
    "        this method divide the dataset into definite number of \n",
    "        training and testing datasets, then save them in a determined path\n",
    "        \"\"\"\n",
    "\n",
    "        # Make a series of the range in which wants to divide the data\n",
    "        start_date = df.index.min()\n",
    "        end_date = df.index.max()\n",
    "        dates = pd.date_range(start=start_date, end=end_date, freq='M')\n",
    "\n",
    "        # Slice around 60% of the dataset for training purpose\n",
    "        train_month_number = int(len(dates) * 0.6) - 1\n",
    "        df_train = df.loc[:dates[train_month_number]]\n",
    "\n",
    "        # add test datasets to the divided dataframe dictionary using dic comprehension\n",
    "        divided_df_dict = {f'df_test{number+1}': df.loc[dates[counter]:dates[counter+1]]\n",
    "                for number, counter in enumerate(range(train_month_number, len(dates) - 1, 1))}\n",
    "        \n",
    "        # add training data to the dictionary\n",
    "        divided_df_dict['df_train'] = df_train\n",
    "\n",
    "        return divided_df_dict\n",
    "\n",
    "    def dataframe_saver(self, df_dict):\n",
    "        \"\"\"\n",
    "        this method saves the dataframes in a path\n",
    "        \"\"\"\n",
    "        output_dir = self.config['output_path']\n",
    "        for df_name in df_dict.keys():\n",
    "            df_dict[df_name].to_csv(os.path.join(output_dir, f'{df_name}.csv'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # run the DataDivider class\n",
    "    divider = DataDivider('config.yaml')\n",
    "    df_dict = divider.dataframe_divider()\n",
    "    divider.dataframe_saver(df_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage I will make DataManager class first, then I will make Model clas\n",
    "\n",
    "## DataManager\n",
    "The necessary steps are borrowed from my educational notebook. Here, I only used the best preprocessing pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
